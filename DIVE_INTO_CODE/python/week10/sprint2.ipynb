{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ディープラーニングフレームワーク2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題1】公式チュートリアルモデルを分担して実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLAによるCIFAR-10の分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XLAとは：<br>\n",
    "線形代数の演算に特化したコンパイラで、XLAを使うことでTensorFlowの演算を最適化し、メモリ使用量、性能、サーバやモバイル環境での移植性の面での改善が期待できます。現在のところ、ほとんどのユーザにとってXLAを使うことによる大きな恩恵は得られないかもしれませんが、just-in-time (JIT) コンパイル機能 や ahead-of-time (AOT) コンパイル機能 を通して、実験的にXLAを使っていただくのは歓迎です。ただし、新たなハードウエアアクセラレータの開発者については、XLAを試してみることをおすすめします。\n",
    "引用サイト：https://www.tensorflow.org/xla/architecture?hl=ja<br>\n",
    "<br>\n",
    "CIFAR-10とは：<br>\n",
    "ラベル「0」： airplane（飛行機）<br>\n",
    "ラベル「1」： automobile（自動車）<br>\n",
    "ラベル「2」： bird（鳥）<br>\n",
    "ラベル「3」： cat（猫）<br>\n",
    "ラベル「4」： deer（鹿）<br>\n",
    "ラベル「5」： dog（犬）<br>\n",
    "ラベル「6」： frog（カエル）<br>\n",
    "ラベル「7」： horse（馬）<br>\n",
    "ラベル「8」： ship（船）<br>\n",
    "ラベル「9」： truck（トラック）<br>\n",
    "という10種類の「物体カラー写真」（乗り物や動物など）の画像データセットである（図1、Alex Krizhevsky氏／Vinod Nair氏／Geoffrey Hinton氏によって、オブジェクト認識用画像データセット「80 Million Tiny Images」から収集されて作成されたサブセットである）。<br>\n",
    "引用サイト：https://www.atmarkit.co.jp/ait/articles/2006/10/news021.html<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 45s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check that GPU is available: cf. https://colab.research.google.com/notebooks/gpu.ipynb\n",
    "# assert(tf.test.gpu_device_name())\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.config.optimizer.set_jit(False) # Start with XLA disabled.\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    x_train = x_train.astype('float32') / 256\n",
    "    x_test = x_test.astype('float32') / 256\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "    return ((x_train, y_train), (x_test, y_test))\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same'),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Activation('softmax')\n",
    "  ])\n",
    "\n",
    "model = generate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 265s 1s/step - loss: 1.9921 - accuracy: 0.2635 - val_loss: 1.7319 - val_accuracy: 0.3839\n",
      "Epoch 1/25\n",
      "196/196 [==============================] - 224s 1s/step - loss: 2.0864 - accuracy: 0.2244 - val_loss: 1.8486 - val_accuracy: 0.3425\n",
      "Epoch 2/25\n",
      "196/196 [==============================] - 201s 1s/step - loss: 1.7604 - accuracy: 0.3605 - val_loss: 1.6426 - val_accuracy: 0.4091\n",
      "Epoch 3/25\n",
      "196/196 [==============================] - 175s 894ms/step - loss: 1.6556 - accuracy: 0.3992 - val_loss: 1.5569 - val_accuracy: 0.4360\n",
      "Epoch 4/25\n",
      "196/196 [==============================] - 178s 907ms/step - loss: 1.5912 - accuracy: 0.4231 - val_loss: 1.4977 - val_accuracy: 0.4543\n",
      "Epoch 5/25\n",
      "196/196 [==============================] - 176s 896ms/step - loss: 1.5382 - accuracy: 0.4442 - val_loss: 1.4594 - val_accuracy: 0.4732\n",
      "Epoch 6/25\n",
      "196/196 [==============================] - 176s 898ms/step - loss: 1.4904 - accuracy: 0.4611 - val_loss: 1.3860 - val_accuracy: 0.4987\n",
      "Epoch 7/25\n",
      "196/196 [==============================] - 173s 883ms/step - loss: 1.4424 - accuracy: 0.4828 - val_loss: 1.3688 - val_accuracy: 0.5095\n",
      "Epoch 8/25\n",
      "196/196 [==============================] - 203s 1s/step - loss: 1.4019 - accuracy: 0.4952 - val_loss: 1.3080 - val_accuracy: 0.5306\n",
      "Epoch 9/25\n",
      "196/196 [==============================] - 172s 877ms/step - loss: 1.3684 - accuracy: 0.5071 - val_loss: 1.4176 - val_accuracy: 0.5041\n",
      "Epoch 10/25\n",
      "196/196 [==============================] - 156s 798ms/step - loss: 1.3368 - accuracy: 0.5222 - val_loss: 1.3990 - val_accuracy: 0.5163\n",
      "Epoch 11/25\n",
      "196/196 [==============================] - 152s 773ms/step - loss: 1.3115 - accuracy: 0.5296 - val_loss: 1.2447 - val_accuracy: 0.5571\n",
      "Epoch 12/25\n",
      "196/196 [==============================] - 142s 723ms/step - loss: 1.2815 - accuracy: 0.5442 - val_loss: 1.2158 - val_accuracy: 0.5665\n",
      "Epoch 13/25\n",
      "196/196 [==============================] - 144s 733ms/step - loss: 1.2564 - accuracy: 0.5550 - val_loss: 1.1955 - val_accuracy: 0.5821\n",
      "Epoch 14/25\n",
      "196/196 [==============================] - 157s 801ms/step - loss: 1.2341 - accuracy: 0.5607 - val_loss: 1.1607 - val_accuracy: 0.5918\n",
      "Epoch 15/25\n",
      "196/196 [==============================] - 172s 877ms/step - loss: 1.2088 - accuracy: 0.5702 - val_loss: 1.1780 - val_accuracy: 0.5806\n",
      "Epoch 16/25\n",
      "196/196 [==============================] - 200s 1s/step - loss: 1.1860 - accuracy: 0.5801 - val_loss: 1.1328 - val_accuracy: 0.5996\n",
      "Epoch 17/25\n",
      "196/196 [==============================] - 206s 1s/step - loss: 1.1667 - accuracy: 0.5865 - val_loss: 1.1095 - val_accuracy: 0.6086\n",
      "Epoch 18/25\n",
      "196/196 [==============================] - 227s 1s/step - loss: 1.1471 - accuracy: 0.5948 - val_loss: 1.0892 - val_accuracy: 0.6198\n",
      "Epoch 19/25\n",
      "196/196 [==============================] - 217s 1s/step - loss: 1.1273 - accuracy: 0.6035 - val_loss: 1.0747 - val_accuracy: 0.6204\n",
      "Epoch 20/25\n",
      "196/196 [==============================] - 193s 985ms/step - loss: 1.1127 - accuracy: 0.6082 - val_loss: 1.0498 - val_accuracy: 0.6339\n",
      "Epoch 21/25\n",
      "196/196 [==============================] - 164s 835ms/step - loss: 1.0911 - accuracy: 0.6172 - val_loss: 1.0286 - val_accuracy: 0.6395\n",
      "Epoch 22/25\n",
      "196/196 [==============================] - 173s 881ms/step - loss: 1.0688 - accuracy: 0.6248 - val_loss: 1.0435 - val_accuracy: 0.6313\n",
      "Epoch 23/25\n",
      "196/196 [==============================] - 181s 923ms/step - loss: 1.0577 - accuracy: 0.6265 - val_loss: 0.9950 - val_accuracy: 0.6543\n",
      "Epoch 24/25\n",
      "196/196 [==============================] - 154s 788ms/step - loss: 1.0380 - accuracy: 0.6334 - val_loss: 1.0097 - val_accuracy: 0.6470\n",
      "Epoch 25/25\n",
      "196/196 [==============================] - 157s 801ms/step - loss: 1.0236 - accuracy: 0.6426 - val_loss: 1.0090 - val_accuracy: 0.6416\n",
      "CPU times: user 2h 46min 2s, sys: 23min 21s, total: 3h 9min 23s\n",
      "Wall time: 1h 15min 1s\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 1.0090 - accuracy: 0.6416\n",
      "Test loss: 1.0090205669403076\n",
      "Test accuracy: 0.6416000127792358\n"
     ]
    }
   ],
   "source": [
    "def compile_model(model):\n",
    "    opt = tf.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = compile_model(model)\n",
    "\n",
    "def train_model(model, x_train, y_train, x_test, y_test, epochs=25):\n",
    "    model.fit(x_train, y_train, batch_size=256, epochs=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
    "\n",
    "def warmup(model, x_train, y_train, x_test, y_test):\n",
    "    # Warm up the JIT, we do not wish to measure the compilation time.\n",
    "    initial_weights = model.get_weights()\n",
    "    train_model(model, x_train, y_train, x_test, y_test, epochs=1)\n",
    "    model.set_weights(initial_weights)\n",
    "\n",
    "warmup(model, x_train, y_train, x_test, y_test)\n",
    "%time train_model(model, x_train, y_train, x_test, y_test)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 146s 745ms/step - loss: 2.0688 - accuracy: 0.2335 - val_loss: 1.9059 - val_accuracy: 0.3072\n",
      "Epoch 1/25\n",
      "196/196 [==============================] - 142s 727ms/step - loss: 2.1339 - accuracy: 0.2069 - val_loss: 1.9553 - val_accuracy: 0.3047\n",
      "Epoch 2/25\n",
      "196/196 [==============================] - 141s 722ms/step - loss: 1.8309 - accuracy: 0.3403 - val_loss: 1.7289 - val_accuracy: 0.3817\n",
      "Epoch 3/25\n",
      "196/196 [==============================] - 142s 722ms/step - loss: 1.6955 - accuracy: 0.3896 - val_loss: 1.7067 - val_accuracy: 0.3886\n",
      "Epoch 4/25\n",
      "196/196 [==============================] - 145s 741ms/step - loss: 1.6116 - accuracy: 0.4163 - val_loss: 1.5962 - val_accuracy: 0.4266\n",
      "Epoch 5/25\n",
      "196/196 [==============================] - 141s 721ms/step - loss: 1.5466 - accuracy: 0.4400 - val_loss: 1.4503 - val_accuracy: 0.4804\n",
      "Epoch 6/25\n",
      "196/196 [==============================] - 139s 711ms/step - loss: 1.4900 - accuracy: 0.4629 - val_loss: 1.4172 - val_accuracy: 0.5002\n",
      "Epoch 7/25\n",
      "196/196 [==============================] - 155s 793ms/step - loss: 1.4495 - accuracy: 0.4751 - val_loss: 1.3712 - val_accuracy: 0.5044\n",
      "Epoch 8/25\n",
      "196/196 [==============================] - 163s 833ms/step - loss: 1.4076 - accuracy: 0.4930 - val_loss: 1.3291 - val_accuracy: 0.5258\n",
      "Epoch 9/25\n",
      "196/196 [==============================] - 139s 711ms/step - loss: 1.3792 - accuracy: 0.5059 - val_loss: 1.3024 - val_accuracy: 0.5366\n",
      "Epoch 10/25\n",
      "196/196 [==============================] - 138s 702ms/step - loss: 1.3442 - accuracy: 0.5222 - val_loss: 1.2889 - val_accuracy: 0.5452\n",
      "Epoch 11/25\n",
      "196/196 [==============================] - 141s 719ms/step - loss: 1.3151 - accuracy: 0.5309 - val_loss: 1.3245 - val_accuracy: 0.5341\n",
      "Epoch 12/25\n",
      "196/196 [==============================] - 142s 724ms/step - loss: 1.2908 - accuracy: 0.5405 - val_loss: 1.2063 - val_accuracy: 0.5711\n",
      "Epoch 13/25\n",
      "196/196 [==============================] - 140s 712ms/step - loss: 1.2583 - accuracy: 0.5528 - val_loss: 1.2489 - val_accuracy: 0.5607\n",
      "Epoch 14/25\n",
      "196/196 [==============================] - 139s 709ms/step - loss: 1.2405 - accuracy: 0.5612 - val_loss: 1.1619 - val_accuracy: 0.5897\n",
      "Epoch 15/25\n",
      "196/196 [==============================] - 140s 712ms/step - loss: 1.2182 - accuracy: 0.5674 - val_loss: 1.1549 - val_accuracy: 0.5938\n",
      "Epoch 16/25\n",
      "196/196 [==============================] - 139s 708ms/step - loss: 1.1979 - accuracy: 0.5765 - val_loss: 1.1394 - val_accuracy: 0.5928\n",
      "Epoch 17/25\n",
      "196/196 [==============================] - 142s 722ms/step - loss: 1.1759 - accuracy: 0.5860 - val_loss: 1.1340 - val_accuracy: 0.5989\n",
      "Epoch 18/25\n",
      "196/196 [==============================] - 140s 716ms/step - loss: 1.1563 - accuracy: 0.5919 - val_loss: 1.0867 - val_accuracy: 0.6155\n",
      "Epoch 19/25\n",
      "196/196 [==============================] - 143s 729ms/step - loss: 1.1342 - accuracy: 0.6016 - val_loss: 1.1027 - val_accuracy: 0.6114\n",
      "Epoch 20/25\n",
      "196/196 [==============================] - 140s 716ms/step - loss: 1.1180 - accuracy: 0.6060 - val_loss: 1.0691 - val_accuracy: 0.6250\n",
      "Epoch 21/25\n",
      "196/196 [==============================] - 141s 720ms/step - loss: 1.1021 - accuracy: 0.6133 - val_loss: 1.0508 - val_accuracy: 0.6344\n",
      "Epoch 22/25\n",
      "196/196 [==============================] - 140s 713ms/step - loss: 1.0811 - accuracy: 0.6219 - val_loss: 1.0464 - val_accuracy: 0.6362\n",
      "Epoch 23/25\n",
      "196/196 [==============================] - 166s 847ms/step - loss: 1.0640 - accuracy: 0.6253 - val_loss: 1.0157 - val_accuracy: 0.6397\n",
      "Epoch 24/25\n",
      "196/196 [==============================] - 183s 934ms/step - loss: 1.0522 - accuracy: 0.6318 - val_loss: 1.0064 - val_accuracy: 0.6436\n",
      "Epoch 25/25\n",
      "196/196 [==============================] - 169s 862ms/step - loss: 1.0360 - accuracy: 0.6397 - val_loss: 0.9768 - val_accuracy: 0.6587\n",
      "CPU times: user 2h 29min 40s, sys: 21min 28s, total: 2h 51min 8s\n",
      "Wall time: 1h 1min 17s\n"
     ]
    }
   ],
   "source": [
    "# We need to clear the session to enable JIT in the middle of the program.\n",
    "tf.keras.backend.clear_session()\n",
    "tf.config.optimizer.set_jit(True) # Enable XLA.\n",
    "model = compile_model(generate_model())\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "warmup(model, x_train, y_train, x_test, y_test)\n",
    "%time train_model(model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題2】（アドバンス課題）様々な手法を実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "後でalbertを読んでみる<br>\n",
    "https://github.com/google-research/ALBERT<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題3】Iris（2値分類）をKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "label = iris.target\n",
    "target_name = iris.target_names\n",
    "all_data = np.concatenate([data, label.reshape(-1, 1)], axis=1)\n",
    "print(target_name)\n",
    "\n",
    "train_df = pd.DataFrame(all_data)\n",
    "train = train_df.iloc[:, :]\n",
    "train.rename(columns={0:'SepalLengthCm', 1:'SepalWidthCm', 2:'PetalLengthCm', 3:'PetalWidthCm', 4:'Species'}, inplace=True)\n",
    "train['Species'].replace(0.0, 'Iris-setosa', inplace=True)\n",
    "train['Species'].replace(1.0, 'Iris-versicolor', inplace=True)\n",
    "train['Species'].replace(2.0, 'Iris-virginica', inplace=True)\n",
    "X = train.loc[50:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = train.loc[50:, ['Species']]\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "# ラベルを数値に変換\n",
    "y[y == \"Iris-versicolor\"] = 0\n",
    "y[y == \"Iris-virginica\"] = 1\n",
    "\n",
    "y = y.astype(np.int64)[:, np.newaxis]\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape = (80, 4)\n",
    "\n",
    "(None, 80, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 20ms/step - loss: 0.8092 - accuracy: 0.5375 - val_loss: 0.6664 - val_accuracy: 0.5000\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.7224 - accuracy: 0.4750 - val_loss: 0.6267 - val_accuracy: 0.6250\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6959 - accuracy: 0.5375 - val_loss: 0.6685 - val_accuracy: 0.6250\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6418 - accuracy: 0.7250 - val_loss: 0.5219 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6140 - accuracy: 0.6500 - val_loss: 0.7652 - val_accuracy: 0.3750\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5344 - accuracy: 0.6875 - val_loss: 0.2949 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4352 - accuracy: 0.8500 - val_loss: 0.0887 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4076 - accuracy: 0.8125 - val_loss: 0.3417 - val_accuracy: 0.8125\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2687 - accuracy: 0.9125 - val_loss: 0.3388 - val_accuracy: 0.8125\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3660 - accuracy: 0.8125 - val_loss: 0.4054 - val_accuracy: 0.8125\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.2368 - accuracy: 0.8875 - val_loss: 0.0799 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1235 - accuracy: 0.9625 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0925 - accuracy: 0.9750 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1895 - accuracy: 0.9375 - val_loss: 0.2561 - val_accuracy: 0.8125\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2381 - accuracy: 0.9125 - val_loss: 0.0645 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0937 - accuracy: 0.9625 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2613 - accuracy: 0.9000 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1600 - accuracy: 0.9500 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1002 - accuracy: 0.9750 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 0.0088 - accuracy: 1.0000WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.209257). Check your callbacks.\n",
      " 2/16 [==>...........................] - ETA: 1s - loss: 0.0123 - accuracy: 1.0000WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.106048). Check your callbacks.\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.1594 - accuracy: 0.9375 - val_loss: 0.0644 - val_accuracy: 0.9375\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1469 - accuracy: 0.9500 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1844 - accuracy: 0.9375 - val_loss: 0.0461 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0714 - accuracy: 0.9875 - val_loss: 0.1026 - val_accuracy: 0.9375\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1569 - accuracy: 0.9500 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.1209 - accuracy: 0.9500 - val_loss: 0.0576 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0916 - accuracy: 0.9625 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0953 - accuracy: 0.9500 - val_loss: 0.0996 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1363 - accuracy: 0.9500 - val_loss: 0.1004 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0938 - accuracy: 0.9500 - val_loss: 0.1265 - val_accuracy: 0.9375\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1096 - accuracy: 0.9625 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0617 - accuracy: 0.9750 - val_loss: 0.0832 - val_accuracy: 0.9375\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.1963 - accuracy: 0.9000 - val_loss: 0.0619 - val_accuracy: 0.9375\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1150 - accuracy: 0.9625 - val_loss: 0.2842 - val_accuracy: 0.8125\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2665 - accuracy: 0.8625 - val_loss: 0.2753 - val_accuracy: 0.8125\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1725 - accuracy: 0.9125 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0835 - accuracy: 0.9750 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1912 - accuracy: 0.9375 - val_loss: 0.1613 - val_accuracy: 0.9375\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2747 - accuracy: 0.9000 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.2007 - accuracy: 0.9125 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.1226 - accuracy: 0.9500 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0654 - accuracy: 0.9875 - val_loss: 0.0570 - val_accuracy: 0.9375\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0665 - accuracy: 0.9625 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.1398 - accuracy: 0.9375 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0890 - accuracy: 0.9625 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0725 - accuracy: 0.9750 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.1642 - accuracy: 0.9500 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.2266 - accuracy: 0.8875 - val_loss: 0.1505 - val_accuracy: 0.9375\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0941 - accuracy: 0.9750 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1194 - accuracy: 0.9500 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0754 - accuracy: 0.9625 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1272 - accuracy: 0.9250 - val_loss: 0.2846 - val_accuracy: 0.8125\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3154 - accuracy: 0.8875 - val_loss: 0.2160 - val_accuracy: 0.8125\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.1015 - accuracy: 0.9750 - val_loss: 0.0618 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0749 - accuracy: 0.9750 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0587 - accuracy: 0.9750 - val_loss: 0.0571 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0770 - accuracy: 0.9750 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0778 - accuracy: 0.9625 - val_loss: 0.1965 - val_accuracy: 0.8125\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.3678 - accuracy: 0.9000 - val_loss: 0.1837 - val_accuracy: 0.8750\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.2452 - accuracy: 0.9250 - val_loss: 0.0874 - val_accuracy: 0.9375\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0933 - accuracy: 0.9625 - val_loss: 0.1572 - val_accuracy: 0.9375\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0676 - accuracy: 0.9750 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1792 - accuracy: 0.9250 - val_loss: 0.1629 - val_accuracy: 0.8750\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1995 - accuracy: 0.8875 - val_loss: 0.2115 - val_accuracy: 0.8125\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1942 - accuracy: 0.9375 - val_loss: 0.0650 - val_accuracy: 0.9375\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0691 - accuracy: 0.9750 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0643 - accuracy: 0.9750 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0779 - accuracy: 0.9750 - val_loss: 0.0775 - val_accuracy: 0.9375\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1758 - accuracy: 0.9125 - val_loss: 0.0651 - val_accuracy: 0.9375\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0723 - accuracy: 0.9625 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0734 - accuracy: 0.9750 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0708 - accuracy: 0.9750 - val_loss: 0.0352 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0695 - accuracy: 0.9625 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0521 - accuracy: 0.9750 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0568 - accuracy: 0.9750 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0542 - accuracy: 0.9750 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0478 - accuracy: 0.9750 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0948 - accuracy: 0.9500 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.2798 - accuracy: 0.9500 - val_loss: 0.0706 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0890 - accuracy: 0.9750 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0781 - accuracy: 0.9625 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0517 - accuracy: 0.9750 - val_loss: 0.0552 - val_accuracy: 0.9375\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1076 - accuracy: 0.9500 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0590 - accuracy: 0.9750 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0679 - accuracy: 0.9625 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0488 - accuracy: 0.9750 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.1122 - accuracy: 0.9625 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0670 - accuracy: 0.9875 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0584 - accuracy: 0.9625 - val_loss: 0.1103 - val_accuracy: 0.9375\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.1780 - accuracy: 0.9500 - val_loss: 0.0804 - val_accuracy: 0.9375\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1332 - accuracy: 0.9500 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0721 - accuracy: 0.9750 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9625 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0879 - accuracy: 0.9625 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1595 - accuracy: 0.9000 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0662 - accuracy: 0.9875 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0632 - accuracy: 0.9750 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0740 - accuracy: 0.9625 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0482 - accuracy: 0.9625 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1074 - accuracy: 0.9500 - val_loss: 0.2649 - val_accuracy: 0.8125\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4330 - accuracy: 0.8875 - val_loss: 0.1437 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.2718 - accuracy: 0.9125 - val_loss: 0.1901 - val_accuracy: 1.0000\n",
      "CPU times: user 12 s, sys: 1.23 s, total: 13.2 s\n",
      "Wall time: 23.7 s\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2480 - accuracy: 0.9000\n",
      "Test loss: 0.24801354110240936\n",
      "Test accuracy: 0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "def generate_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, input_dim=X_train.shape[1]),\n",
    "#     tf.keras.layers.Activation('relu'),\n",
    "#     tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(1),\n",
    "    tf.keras.layers.Activation('sigmoid')\n",
    "  ])\n",
    "\n",
    "model = generate_model()\n",
    "\n",
    "\n",
    "def compile_model(model):\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = compile_model(model)\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=100):\n",
    "    model.fit(X_train, y_train, batch_size=5, epochs=epochs, validation_data=(X_val, y_val), shuffle=True)\n",
    "\n",
    "def warmup(model, X_train, y_train, X_test, y_test):\n",
    "    # Warm up the JIT, we do not wish to measure the compilation time.\n",
    "    initial_weights = model.get_weights()\n",
    "    train_model(model, X_train, y_train, X_test, y_test, epochs=1)\n",
    "    model.set_weights(initial_weights)\n",
    "\n",
    "warmup(model, X_train, y_train, X_test, y_test)\n",
    "%time train_model(model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題4】Iris（多値分類）をKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# tf.keras.backend.clear_session()\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "label = iris.target\n",
    "target_name = iris.target_names\n",
    "all_data = np.concatenate([data, label.reshape(-1, 1)], axis=1)\n",
    "print(target_name)\n",
    "\n",
    "train_df = pd.DataFrame(all_data)\n",
    "train = train_df\n",
    "train.rename(columns={0:'SepalLengthCm', 1:'SepalWidthCm', 2:'PetalLengthCm', 3:'PetalWidthCm', 4:'Species'}, inplace=True)\n",
    "train['Species'].replace(0.0, 'Iris-setosa', inplace=True)\n",
    "train['Species'].replace(1.0, 'Iris-versicolor', inplace=True)\n",
    "train['Species'].replace(2.0, 'Iris-virginica', inplace=True)\n",
    "X = train.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = train.loc[:, ['Species']]\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "# ラベルを数値に変換\n",
    "y[y == \"Iris-setosa\"] = 0\n",
    "y[y == \"Iris-versicolor\"] = 1\n",
    "y[y == \"Iris-virginica\"] = 2\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=3)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 16ms/step - loss: 1.0137 - accuracy: 0.5667 - val_loss: 0.4225 - val_accuracy: 0.8000\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.3877 - accuracy: 0.6667 - val_loss: 0.4998 - val_accuracy: 0.6250\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5092 - accuracy: 0.6458 - val_loss: 0.4202 - val_accuracy: 0.7083\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.7231 - accuracy: 0.7708 - val_loss: 0.5183 - val_accuracy: 0.6250\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.8229 - val_loss: 0.3822 - val_accuracy: 0.9167\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4223 - accuracy: 0.7812 - val_loss: 0.6223 - val_accuracy: 0.7083\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8646 - val_loss: 1.6706 - val_accuracy: 0.7083\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3685 - accuracy: 0.8854 - val_loss: 0.2087 - val_accuracy: 0.8750\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5569 - accuracy: 0.8333 - val_loss: 0.4956 - val_accuracy: 0.7083\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.7500 - val_loss: 0.3783 - val_accuracy: 0.8333\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.3136 - accuracy: 0.8542 - val_loss: 0.3827 - val_accuracy: 0.9167\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5821 - accuracy: 0.8646 - val_loss: 0.4085 - val_accuracy: 0.9167\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4438 - accuracy: 0.88 - 0s 6ms/step - loss: 0.4304 - accuracy: 0.8958 - val_loss: 0.2025 - val_accuracy: 0.9167\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2042 - accuracy: 0.9375 - val_loss: 0.2182 - val_accuracy: 0.9167\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3491 - accuracy: 0.9271 - val_loss: 0.2846 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2948 - accuracy: 0.9271 - val_loss: 0.2110 - val_accuracy: 0.9167\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.7564 - accuracy: 0.8958 - val_loss: 0.2324 - val_accuracy: 0.9167\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1376 - accuracy: 0.9479 - val_loss: 0.4970 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2786 - accuracy: 0.9062 - val_loss: 0.1991 - val_accuracy: 0.9167\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1914 - accuracy: 0.9062 - val_loss: 0.5777 - val_accuracy: 0.7917\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1522 - accuracy: 0.9375 - val_loss: 0.2168 - val_accuracy: 0.9167\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2023 - accuracy: 0.8958 - val_loss: 0.2318 - val_accuracy: 0.8750\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2880 - accuracy: 0.9375 - val_loss: 0.3415 - val_accuracy: 0.9167\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2348 - accuracy: 0.9167 - val_loss: 0.6206 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.1891 - accuracy: 0.9167 - val_loss: 0.1895 - val_accuracy: 0.9167\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1235 - accuracy: 0.9375 - val_loss: 0.3571 - val_accuracy: 0.9167\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1926 - accuracy: 0.9479 - val_loss: 0.1693 - val_accuracy: 0.9167\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.9375 - val_loss: 0.1822 - val_accuracy: 0.9167\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1309 - accuracy: 0.9271 - val_loss: 0.1935 - val_accuracy: 0.9167\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2919 - accuracy: 0.9271 - val_loss: 0.1548 - val_accuracy: 0.9167\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1296 - accuracy: 0.9583 - val_loss: 0.2772 - val_accuracy: 0.9167\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1831 - accuracy: 0.9688 - val_loss: 1.9625 - val_accuracy: 0.6250\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2693 - accuracy: 0.9062 - val_loss: 0.1599 - val_accuracy: 0.9167\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.2395 - accuracy: 0.9375 - val_loss: 0.2099 - val_accuracy: 0.9167\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2068 - accuracy: 0.9792 - val_loss: 0.4441 - val_accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0868 - accuracy: 0.9688 - val_loss: 0.4237 - val_accuracy: 0.9167\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.2117 - accuracy: 0.9271 - val_loss: 0.2293 - val_accuracy: 0.9167\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.9271 - val_loss: 0.6854 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2342 - accuracy: 0.9271 - val_loss: 0.4064 - val_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1914 - accuracy: 0.9375 - val_loss: 0.1754 - val_accuracy: 0.9167\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2337 - accuracy: 0.9375 - val_loss: 0.4074 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0875 - accuracy: 0.9583 - val_loss: 0.6486 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3126 - accuracy: 0.9167 - val_loss: 0.1750 - val_accuracy: 0.9167\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.1448 - accuracy: 0.9375 - val_loss: 0.2472 - val_accuracy: 0.8750\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.0675 - accuracy: 0.9688 - val_loss: 2.7124 - val_accuracy: 0.7083\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1416 - accuracy: 0.9167 - val_loss: 0.2170 - val_accuracy: 0.9167\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1380 - accuracy: 0.9479 - val_loss: 0.2819 - val_accuracy: 0.9167\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1681 - accuracy: 0.9271 - val_loss: 0.5311 - val_accuracy: 0.8750\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2076 - accuracy: 0.9375 - val_loss: 0.2173 - val_accuracy: 0.9167\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0804 - accuracy: 0.9792 - val_loss: 0.1789 - val_accuracy: 0.9167\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.3063 - accuracy: 0.9062 - val_loss: 0.2573 - val_accuracy: 0.9167\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1271 - accuracy: 0.9479 - val_loss: 0.1982 - val_accuracy: 0.9167\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9583 - val_loss: 0.4076 - val_accuracy: 0.9167\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.9479 - val_loss: 0.4287 - val_accuracy: 0.9167\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0561 - accuracy: 0.9792 - val_loss: 0.4308 - val_accuracy: 0.8750\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2412 - accuracy: 0.9167 - val_loss: 1.2833 - val_accuracy: 0.6250\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.2090 - accuracy: 0.8958 - val_loss: 0.1519 - val_accuracy: 0.9167\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1909 - accuracy: 0.9792 - val_loss: 0.3570 - val_accuracy: 0.9167\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.1285 - accuracy: 0.9375 - val_loss: 0.5996 - val_accuracy: 0.9167\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1570 - accuracy: 0.9583 - val_loss: 0.1594 - val_accuracy: 0.9167\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2681 - accuracy: 0.9479 - val_loss: 0.1886 - val_accuracy: 0.9167\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1224 - accuracy: 0.9375 - val_loss: 0.1386 - val_accuracy: 0.9167\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3836 - accuracy: 0.9271 - val_loss: 1.1640 - val_accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1177 - accuracy: 0.9688 - val_loss: 0.3738 - val_accuracy: 0.9167\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.2032 - accuracy: 0.9583 - val_loss: 0.2069 - val_accuracy: 0.9167\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.2889 - accuracy: 0.9583 - val_loss: 0.2104 - val_accuracy: 0.8750\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0949 - accuracy: 0.9375 - val_loss: 0.2879 - val_accuracy: 0.8750\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1354 - accuracy: 0.9688 - val_loss: 0.3508 - val_accuracy: 0.9167\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1649 - accuracy: 0.9271 - val_loss: 0.1767 - val_accuracy: 0.9167\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 4.6386 - accuracy: 0.9167 - val_loss: 0.1483 - val_accuracy: 0.9167\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9792 - val_loss: 0.4632 - val_accuracy: 0.9167\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9479 - val_loss: 0.1710 - val_accuracy: 0.9167\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1755 - accuracy: 0.9375 - val_loss: 0.2291 - val_accuracy: 0.9167\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1489 - accuracy: 0.9479 - val_loss: 0.1760 - val_accuracy: 0.9167\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.0759 - accuracy: 0.9583 - val_loss: 0.9342 - val_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1929 - accuracy: 0.9479 - val_loss: 0.9792 - val_accuracy: 0.7917\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3.6572 - accuracy: 0.9062 - val_loss: 0.2466 - val_accuracy: 0.9167\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0664 - accuracy: 0.9688 - val_loss: 0.2333 - val_accuracy: 0.8750\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0996 - accuracy: 0.9583 - val_loss: 0.3403 - val_accuracy: 0.9167\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.9375 - val_loss: 0.1595 - val_accuracy: 0.9583\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.0510 - accuracy: 0.9792 - val_loss: 0.1790 - val_accuracy: 0.9167\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.1368 - accuracy: 0.9583 - val_loss: 0.8899 - val_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1079 - accuracy: 0.9688 - val_loss: 0.2470 - val_accuracy: 0.9167\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.2071 - accuracy: 0.9167 - val_loss: 0.2939 - val_accuracy: 0.9167\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9792 - val_loss: 0.5205 - val_accuracy: 0.9167\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1978 - accuracy: 0.9167 - val_loss: 1.5703 - val_accuracy: 0.6250\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.2373 - accuracy: 0.9479 - val_loss: 0.1731 - val_accuracy: 0.9167\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3118 - accuracy: 0.9271 - val_loss: 0.3508 - val_accuracy: 0.9167\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0995 - accuracy: 0.9479 - val_loss: 0.1770 - val_accuracy: 0.9167\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.1191 - accuracy: 0.9479 - val_loss: 0.3216 - val_accuracy: 0.8333\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1671 - accuracy: 0.9375 - val_loss: 0.1598 - val_accuracy: 0.9167\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.1823 - accuracy: 0.9375 - val_loss: 0.2146 - val_accuracy: 0.9167\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.0439 - accuracy: 0.9896 - val_loss: 0.2478 - val_accuracy: 0.9167\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1731 - accuracy: 0.9375 - val_loss: 0.3222 - val_accuracy: 0.9167\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0953 - accuracy: 0.9688 - val_loss: 0.3941 - val_accuracy: 0.9167\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 2.2833 - accuracy: 0.8646 - val_loss: 0.3844 - val_accuracy: 0.8333\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.4515 - accuracy: 0.9375 - val_loss: 0.4589 - val_accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.1668 - accuracy: 0.9271 - val_loss: 0.2336 - val_accuracy: 0.9167\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.3429 - accuracy: 0.9375 - val_loss: 0.2368 - val_accuracy: 0.9167\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.0772 - accuracy: 0.9479 - val_loss: 0.1705 - val_accuracy: 0.8750\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1860 - accuracy: 0.9688 - val_loss: 0.2913 - val_accuracy: 0.9167\n",
      "CPU times: user 11.9 s, sys: 1.13 s, total: 13.1 s\n",
      "Wall time: 15.3 s\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0742 - accuracy: 0.9667\n",
      "Test loss: 0.07424275577068329\n",
      "Test accuracy: 0.9666666388511658\n"
     ]
    }
   ],
   "source": [
    "def generate_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, input_shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(3),\n",
    "    tf.keras.layers.Activation('softmax')\n",
    "  ])\n",
    "\n",
    "model = generate_model()\n",
    "\n",
    "\n",
    "def compile_model(model):\n",
    "    opt = tf.keras.optimizers.RMSprop(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = compile_model(model)\n",
    "\n",
    "def train_model(model, X_train2, y_train2, X_val, y_val, epochs=100):\n",
    "    model.fit(X_train2, y_train2, batch_size=5, epochs=epochs, validation_data=(X_val, y_val), shuffle=True)\n",
    "\n",
    "def warmup(model, X_train, y_train, X_test, y_test):\n",
    "    # Warm up the JIT, we do not wish to measure the compilation time.\n",
    "    initial_weights = model.get_weights()\n",
    "    train_model(model, X_train, y_train, X_test, y_test, epochs=1)\n",
    "    model.set_weights(initial_weights)\n",
    "\n",
    "warmup(model, X_train, y_train, X_test, y_test)\n",
    "%time train_model(model, X_train2, y_train2, X_val, y_val)\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題5】House PricesをKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-52-702553b0d5d4>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['GrLivArea'] = X['GrLivArea'].apply(np.log)\n",
      "<ipython-input-52-702553b0d5d4>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y['SalePrice'] = y['SalePrice'].apply(np.log)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "DIR_PATH = '/Users/sasanoshouta/Desktop/DIVE_INTO_CODE/python/week3/house-prices-advanced-regression-techniques/'\n",
    "train_df = pd.read_csv(DIR_PATH+'train.csv')\n",
    "test_df = pd.read_csv(DIR_PATH+'test.csv')\n",
    "\n",
    "X = train_df[['GrLivArea', 'YearBuilt']]\n",
    "y = train_df[['SalePrice']]\n",
    "X['GrLivArea'] = X['GrLivArea'].apply(np.log)\n",
    "y['SalePrice'] = y['SalePrice'].apply(np.log)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 1s 3ms/step - loss: 1874.5500 - val_loss: 0.1134\n",
      "Epoch 1/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 1095.1494 - val_loss: 0.1902\n",
      "Epoch 2/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.3445 - val_loss: 0.1262\n",
      "Epoch 3/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.4656 - val_loss: 1.4793\n",
      "Epoch 4/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.5421 - val_loss: 0.5668\n",
      "Epoch 5/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.5961 - val_loss: 0.3431\n",
      "Epoch 6/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6197 - val_loss: 0.1720\n",
      "Epoch 7/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.6533 - val_loss: 0.1127\n",
      "Epoch 8/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.4072 - val_loss: 0.2100\n",
      "Epoch 9/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.4301 - val_loss: 0.9874\n",
      "Epoch 10/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.5840 - val_loss: 0.3230\n",
      "Epoch 11/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6277 - val_loss: 0.3912\n",
      "Epoch 12/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.1724\n",
      "Epoch 13/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.5560 - val_loss: 2.1297\n",
      "Epoch 14/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.7107 - val_loss: 0.2514\n",
      "Epoch 15/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.4691 - val_loss: 0.1206\n",
      "Epoch 16/100\n",
      "187/187 [==============================] - 0s 3ms/step - loss: 0.6117 - val_loss: 1.1743\n",
      "Epoch 17/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.7004 - val_loss: 0.7099\n",
      "Epoch 18/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.4241 - val_loss: 2.4108\n",
      "Epoch 19/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.3906 - val_loss: 0.2950\n",
      "Epoch 20/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2953 - val_loss: 0.1108\n",
      "Epoch 21/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.8500 - val_loss: 0.1186\n",
      "Epoch 22/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2400 - val_loss: 0.1464\n",
      "Epoch 23/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3150 - val_loss: 0.6829\n",
      "Epoch 24/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.4359 - val_loss: 0.5368\n",
      "Epoch 25/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2369 - val_loss: 0.5588\n",
      "Epoch 26/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2689 - val_loss: 0.2121\n",
      "Epoch 27/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.7164 - val_loss: 1.9604\n",
      "Epoch 28/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.4232 - val_loss: 0.1133\n",
      "Epoch 29/100\n",
      "187/187 [==============================] - 0s 3ms/step - loss: 0.4391 - val_loss: 0.2573\n",
      "Epoch 30/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2174 - val_loss: 0.3212\n",
      "Epoch 31/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.4217 - val_loss: 1.3108\n",
      "Epoch 32/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.3006 - val_loss: 0.3885\n",
      "Epoch 33/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.4746 - val_loss: 0.2785\n",
      "Epoch 34/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2857 - val_loss: 0.4297\n",
      "Epoch 35/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.4301 - val_loss: 0.6185\n",
      "Epoch 36/100\n",
      "187/187 [==============================] - 0s 3ms/step - loss: 0.3973 - val_loss: 0.8216\n",
      "Epoch 37/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3937 - val_loss: 0.9651\n",
      "Epoch 38/100\n",
      "187/187 [==============================] - 1s 4ms/step - loss: 0.3176 - val_loss: 0.3465\n",
      "Epoch 39/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2603 - val_loss: 0.1431\n",
      "Epoch 40/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2540 - val_loss: 0.1359\n",
      "Epoch 41/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2159 - val_loss: 0.1564\n",
      "Epoch 42/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1665 - val_loss: 0.1240\n",
      "Epoch 43/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1789 - val_loss: 0.1100\n",
      "Epoch 44/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2813 - val_loss: 0.1098\n",
      "Epoch 45/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.3404 - val_loss: 0.2548\n",
      "Epoch 46/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2140 - val_loss: 0.1174\n",
      "Epoch 47/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1672 - val_loss: 0.2696\n",
      "Epoch 48/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.1884 - val_loss: 0.1456\n",
      "Epoch 49/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2642 - val_loss: 0.2452\n",
      "Epoch 50/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2084 - val_loss: 0.2567\n",
      "Epoch 51/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2380 - val_loss: 0.2171\n",
      "Epoch 52/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2057 - val_loss: 0.1329\n",
      "Epoch 53/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2539 - val_loss: 0.1092\n",
      "Epoch 54/100\n",
      "187/187 [==============================] - 0s 3ms/step - loss: 0.1913 - val_loss: 0.3132\n",
      "Epoch 55/100\n",
      "187/187 [==============================] - 1s 4ms/step - loss: 0.2084 - val_loss: 0.1395\n",
      "Epoch 56/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2185 - val_loss: 0.2617\n",
      "Epoch 57/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.3113 - val_loss: 0.1088\n",
      "Epoch 58/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2155 - val_loss: 0.1867\n",
      "Epoch 59/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2797 - val_loss: 0.1467\n",
      "Epoch 60/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.3135 - val_loss: 0.1085\n",
      "Epoch 61/100\n",
      "187/187 [==============================] - 0s 3ms/step - loss: 0.2274 - val_loss: 0.4524\n",
      "Epoch 62/100\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 0.2575 - val_loss: 0.2036\n",
      "Epoch 63/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3240 - val_loss: 0.2654\n",
      "Epoch 64/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2082 - val_loss: 0.4780\n",
      "Epoch 65/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2114 - val_loss: 0.1088\n",
      "Epoch 66/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1673 - val_loss: 0.1595\n",
      "Epoch 67/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2750 - val_loss: 0.4581\n",
      "Epoch 68/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2969 - val_loss: 0.5522\n",
      "Epoch 69/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2512 - val_loss: 0.4579\n",
      "Epoch 70/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2983 - val_loss: 0.7827\n",
      "Epoch 71/100\n",
      "187/187 [==============================] - 0s 3ms/step - loss: 0.3075 - val_loss: 0.3336\n",
      "Epoch 72/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2659 - val_loss: 0.1964\n",
      "Epoch 73/100\n",
      "187/187 [==============================] - 1s 4ms/step - loss: 0.7772 - val_loss: 0.1277\n",
      "Epoch 74/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2233 - val_loss: 0.3038\n",
      "Epoch 75/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1993 - val_loss: 0.1086\n",
      "Epoch 76/100\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 0.2492 - val_loss: 0.1097\n",
      "Epoch 77/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2187 - val_loss: 0.1255\n",
      "Epoch 78/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2191 - val_loss: 0.1585\n",
      "Epoch 79/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2164 - val_loss: 0.1544\n",
      "Epoch 80/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2915 - val_loss: 0.1131\n",
      "Epoch 81/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2138 - val_loss: 0.1130\n",
      "Epoch 82/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2561 - val_loss: 0.5474\n",
      "Epoch 83/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.6108 - val_loss: 0.5569\n",
      "Epoch 84/100\n",
      "187/187 [==============================] - 0s 3ms/step - loss: 0.2359 - val_loss: 0.3189\n",
      "Epoch 85/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2191 - val_loss: 0.1086\n",
      "Epoch 86/100\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 0.2304 - val_loss: 0.1637\n",
      "Epoch 87/100\n",
      "187/187 [==============================] - 0s 3ms/step - loss: 0.1905 - val_loss: 0.1200\n",
      "Epoch 88/100\n",
      "187/187 [==============================] - 1s 4ms/step - loss: 0.2119 - val_loss: 0.2752\n",
      "Epoch 89/100\n",
      "187/187 [==============================] - 1s 4ms/step - loss: 0.2297 - val_loss: 0.1370\n",
      "Epoch 90/100\n",
      "187/187 [==============================] - 1s 4ms/step - loss: 0.2367 - val_loss: 0.2409\n",
      "Epoch 91/100\n",
      "187/187 [==============================] - 1s 4ms/step - loss: 0.2508 - val_loss: 0.1463\n",
      "Epoch 92/100\n",
      "187/187 [==============================] - 1s 4ms/step - loss: 0.2352 - val_loss: 0.1604\n",
      "Epoch 93/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2150 - val_loss: 0.3446\n",
      "Epoch 94/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.4185 - val_loss: 0.1106\n",
      "Epoch 95/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1903 - val_loss: 0.1801\n",
      "Epoch 96/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2713 - val_loss: 0.1103\n",
      "Epoch 97/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2166 - val_loss: 0.1740\n",
      "Epoch 98/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2296 - val_loss: 0.1733\n",
      "Epoch 99/100\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2529 - val_loss: 0.2241\n",
      "Epoch 100/100\n",
      "187/187 [==============================] - 0s 2ms/step - loss: 0.2284 - val_loss: 0.2162\n",
      "CPU times: user 55.5 s, sys: 7.85 s, total: 1min 3s\n",
      "Wall time: 50.7 s\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1976\n",
      "Test mse: 0.1976182758808136\n"
     ]
    }
   ],
   "source": [
    "def generate_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, input_shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "model = generate_model()\n",
    "\n",
    "\n",
    "def compile_model(model):\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.01)\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                optimizer=opt)\n",
    "    return model\n",
    "\n",
    "model = compile_model(model)\n",
    "\n",
    "def train_model(model, X_train2, y_train2, X_val, y_val, epochs=100):\n",
    "    model.fit(X_train2, y_train2, batch_size=5, epochs=epochs, validation_data=(X_val, y_val), shuffle=True)\n",
    "\n",
    "def warmup(model, X_train, y_train, X_test, y_test):\n",
    "    # Warm up the JIT, we do not wish to measure the compilation time.\n",
    "    initial_weights = model.get_weights()\n",
    "    train_model(model, X_train, y_train, X_test, y_test, epochs=1)\n",
    "    model.set_weights(initial_weights)\n",
    "\n",
    "warmup(model, X_train, y_train, X_test, y_test)\n",
    "%time train_model(model, X_train2, y_train2, X_val, y_val)\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test mse:', scores)\n",
    "# print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題6】MNISTをKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def load_mnist():\n",
    "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    X_train = X_train.astype('float32') / 256\n",
    "    X_test = X_test.astype('float32') / 256\n",
    "    X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "    X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "    return ((X_train, y_train), (X_test, y_test))\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape = (60000, 28, 28)\n",
    "(sample, h, w, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 149s 744ms/step - loss: 2.3061 - accuracy: 0.1112 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 1/25\n",
      "200/200 [==============================] - 137s 686ms/step - loss: 0.8151 - accuracy: 0.7266 - val_loss: 0.2419 - val_accuracy: 0.9306\n",
      "Epoch 2/25\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 0.3910 - accuracy: 0.8748 - val_loss: 0.1484 - val_accuracy: 0.9566\n",
      "Epoch 3/25\n",
      "200/200 [==============================] - 122s 612ms/step - loss: 0.2675 - accuracy: 0.9179 - val_loss: 0.1090 - val_accuracy: 0.9683\n",
      "Epoch 4/25\n",
      "200/200 [==============================] - 121s 603ms/step - loss: 0.2099 - accuracy: 0.9350 - val_loss: 0.1252 - val_accuracy: 0.9644\n",
      "Epoch 5/25\n",
      "200/200 [==============================] - 120s 601ms/step - loss: 0.1878 - accuracy: 0.9429 - val_loss: 0.0666 - val_accuracy: 0.9825\n",
      "Epoch 6/25\n",
      "200/200 [==============================] - 130s 648ms/step - loss: 0.1719 - accuracy: 0.9467 - val_loss: 0.0574 - val_accuracy: 0.9828\n",
      "Epoch 7/25\n",
      "200/200 [==============================] - 128s 642ms/step - loss: 0.1749 - accuracy: 0.9470 - val_loss: 0.0784 - val_accuracy: 0.9758\n",
      "Epoch 8/25\n",
      "200/200 [==============================] - 124s 621ms/step - loss: 0.1619 - accuracy: 0.9515 - val_loss: 0.0556 - val_accuracy: 0.9834\n",
      "Epoch 9/25\n",
      "200/200 [==============================] - 124s 618ms/step - loss: 0.1607 - accuracy: 0.9510 - val_loss: 0.0520 - val_accuracy: 0.9842\n",
      "Epoch 10/25\n",
      "200/200 [==============================] - 124s 621ms/step - loss: 0.1565 - accuracy: 0.9529 - val_loss: 0.0664 - val_accuracy: 0.9837\n",
      "Epoch 11/25\n",
      "200/200 [==============================] - 156s 780ms/step - loss: 0.1521 - accuracy: 0.9547 - val_loss: 0.0697 - val_accuracy: 0.9822\n",
      "Epoch 12/25\n",
      "200/200 [==============================] - 197s 983ms/step - loss: 0.1440 - accuracy: 0.9575 - val_loss: 0.0517 - val_accuracy: 0.9859\n",
      "Epoch 13/25\n",
      "200/200 [==============================] - 195s 973ms/step - loss: 0.1461 - accuracy: 0.9569 - val_loss: 0.0502 - val_accuracy: 0.9855\n",
      "Epoch 14/25\n",
      "200/200 [==============================] - 219s 1s/step - loss: 0.1424 - accuracy: 0.9566 - val_loss: 0.0616 - val_accuracy: 0.9836\n",
      "Epoch 15/25\n",
      "200/200 [==============================] - 192s 961ms/step - loss: 0.1513 - accuracy: 0.9558 - val_loss: 0.0530 - val_accuracy: 0.9858\n",
      "Epoch 16/25\n",
      "200/200 [==============================] - 227s 1s/step - loss: 0.1388 - accuracy: 0.9590 - val_loss: 0.0429 - val_accuracy: 0.9869\n",
      "Epoch 17/25\n",
      "200/200 [==============================] - 248s 1s/step - loss: 0.1354 - accuracy: 0.9599 - val_loss: 0.0624 - val_accuracy: 0.9831\n",
      "Epoch 18/25\n",
      "200/200 [==============================] - 246s 1s/step - loss: 0.1308 - accuracy: 0.9610 - val_loss: 0.0471 - val_accuracy: 0.9868\n",
      "Epoch 19/25\n",
      "200/200 [==============================] - 224s 1s/step - loss: 0.1401 - accuracy: 0.9576 - val_loss: 0.0555 - val_accuracy: 0.9852\n",
      "Epoch 20/25\n",
      "200/200 [==============================] - 208s 1s/step - loss: 0.1359 - accuracy: 0.9596 - val_loss: 0.0592 - val_accuracy: 0.9847\n",
      "Epoch 21/25\n",
      "200/200 [==============================] - 192s 961ms/step - loss: 0.1404 - accuracy: 0.9579 - val_loss: 0.0549 - val_accuracy: 0.9862\n",
      "Epoch 22/25\n",
      "200/200 [==============================] - 205s 1s/step - loss: 0.1383 - accuracy: 0.9591 - val_loss: 0.0468 - val_accuracy: 0.9863\n",
      "Epoch 23/25\n",
      "200/200 [==============================] - 166s 830ms/step - loss: 0.1378 - accuracy: 0.9589 - val_loss: 0.0518 - val_accuracy: 0.9853\n",
      "Epoch 24/25\n",
      "200/200 [==============================] - 158s 789ms/step - loss: 0.1356 - accuracy: 0.9599 - val_loss: 0.0500 - val_accuracy: 0.9845\n",
      "Epoch 25/25\n",
      "200/200 [==============================] - 245s 1s/step - loss: 0.1315 - accuracy: 0.9610 - val_loss: 0.0460 - val_accuracy: 0.9876\n",
      "CPU times: user 2h 14min 18s, sys: 22min 47s, total: 2h 37min 6s\n",
      "Wall time: 1h 12min 54s\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 0.0460 - accuracy: 0.9876\n",
      "Test loss: 0.04596419632434845\n",
      "Test accuracy: 0.9876000285148621\n"
     ]
    }
   ],
   "source": [
    "def generate_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', input_shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same'),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Activation('softmax')\n",
    "  ])\n",
    "\n",
    "model = generate_model()\n",
    "\n",
    "def compile_model(model):\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.01, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = compile_model(model)\n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, epochs=25):\n",
    "    model.fit(X_train, y_train, batch_size=300, epochs=epochs, validation_data=(X_test, y_test), shuffle=True)\n",
    "\n",
    "def warmup(model, X_train, y_train, X_test, y_test):\n",
    "    # Warm up the JIT, we do not wish to measure the compilation time.\n",
    "    initial_weights = model.get_weights()\n",
    "    train_model(model, X_train, y_train, X_test, y_test, epochs=1)\n",
    "    model.set_weights(initial_weights)\n",
    "\n",
    "warmup(model, X_train, y_train, X_test, y_test)\n",
    "%time train_model(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "履歴の可視化：https://tensorflow.classcat.com/2018/08/26/tensorflow-tutorials-keras-basic-regression/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題7】（アドバンス課題）PyTorchへの書き換え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題8】（アドバンス課題）フレームワークの比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
