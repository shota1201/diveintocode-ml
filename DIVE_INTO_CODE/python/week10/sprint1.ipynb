{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sprint1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wW6glrDY8YgV"
      },
      "source": [
        "# Sprint ディープラーニングフレームワーク1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szRiF3zH8RyW",
        "outputId": "63e9a2fd-cea5-4596-8682-4da42b93783b"
      },
      "source": [
        "!pip install --upgrade tensorflow==1.15.0"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow==1.15.0 in /usr/local/lib/python3.7/dist-packages (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.1)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (54.0.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.2)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0KiOCt98i47"
      },
      "source": [
        "【問題1】スクラッチを振り返る<br>\n",
        "・重みの初期化が必要だった<br>\n",
        "・エポックループが必要だった<br>\n",
        "・層の構築が必要だった<br>\n",
        "・各関数において、forward, backward構築が必要だった<br>\n",
        "・最適化手法を用意して重みを更新する必要があった<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqbbMWzE9xAf"
      },
      "source": [
        "# データセットの用意"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "yk_Hmva_8hca",
        "outputId": "ce2732b2-9486-47ef-83a4-95a9b4319ef6"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "iris = load_iris()\n",
        "data = iris.data\n",
        "label = iris.target\n",
        "target_name = iris.target_names\n",
        "all_data = np.concatenate([data, label.reshape(-1, 1)], axis=1)\n",
        "print(target_name)\n",
        "\n",
        "train_df = pd.DataFrame(all_data)\n",
        "train = train_df.iloc[50:, :]\n",
        "train.rename(columns={0:'SepalLengthCm', 1:'SepalWidthCm', 2:'PetalLengthCm', 3:'PetalWidthCm', 4:'Species'}, inplace=True)\n",
        "train['Species'].replace(1.0, 'Iris-versicolor', inplace=True)\n",
        "train['Species'].replace(2.0, 'Iris-virginica', inplace=True)\n",
        "train"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>7.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.7</td>\n",
              "      <td>1.4</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>6.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>6.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.5</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>5.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>6.5</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.6</td>\n",
              "      <td>1.5</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm          Species\n",
              "50             7.0           3.2            4.7           1.4  Iris-versicolor\n",
              "51             6.4           3.2            4.5           1.5  Iris-versicolor\n",
              "52             6.9           3.1            4.9           1.5  Iris-versicolor\n",
              "53             5.5           2.3            4.0           1.3  Iris-versicolor\n",
              "54             6.5           2.8            4.6           1.5  Iris-versicolor\n",
              "..             ...           ...            ...           ...              ...\n",
              "145            6.7           3.0            5.2           2.3   Iris-virginica\n",
              "146            6.3           2.5            5.0           1.9   Iris-virginica\n",
              "147            6.5           3.0            5.2           2.0   Iris-virginica\n",
              "148            6.2           3.4            5.4           2.3   Iris-virginica\n",
              "149            5.9           3.0            5.1           1.8   Iris-virginica\n",
              "\n",
              "[100 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJm1yTFYMpXU"
      },
      "source": [
        "【問題2】スクラッチとTensorFlowの対応を考える<br>\n",
        "・重みの初期化が必要だった<br>\n",
        "→重みの初期化は変わらず必要である。TensorFlowでは、パラメータとして設定する形になっている<br>\n",
        "・エポックループが必要だった<br>\n",
        "→エポックループも変わらずに必要。ここはスクラッチ実装と大きく変わらない<br>\n",
        "・層の構築が必要だった<br>\n",
        "→ここも必要ではあるが、スクラッチ実装よりも手軽に層の追加・編集がLayer.add機能で行えるようになっている。<br>\n",
        "・各関数において、forward, backward構築が必要だった<br>\n",
        "→一度Layer.addで任意の層を構築すると、実行時に自動的に順伝搬・逆伝搬で学習が行われるようになっている。<br>\n",
        "・最適化手法を用意して重みを更新する必要があった<br>\n",
        "→最適化手法が用意されており、その範囲のものを使う分には、スクラッチで実装する必要がなくなっている。<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BieACCTE9Rh9",
        "outputId": "e44c51b3-5077-4870-cc18-cb111a2d27ea"
      },
      "source": [
        "\"\"\"\n",
        "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "# データセットの読み込み\n",
        "# df = pd.read_csv(\"Iris.csv\")\n",
        "df = train\n",
        "# データフレームから条件抽出\n",
        "df = df[(df[\"Species\"] == \"Iris-versicolor\") | (df[\"Species\"] == \"Iris-virginica\")]\n",
        "y = df[\"Species\"]\n",
        "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
        "# NumPy 配列に変換\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "# ラベルを数値に変換\n",
        "y[y == \"Iris-versicolor\"] = 0\n",
        "y[y == \"Iris-virginica\"] = 1\n",
        "y = y.astype(np.int64)[:, np.newaxis]\n",
        "# trainとtestに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "# さらにtrainとvalに分割\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "    ミニバッチを取得するイテレータ\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : 次の形のndarray, shape (n_samples, n_features)\n",
        "      訓練データ\n",
        "    y : 次の形のndarray, shape (n_samples, 1)\n",
        "      正解値\n",
        "    batch_size : int\n",
        "      バッチサイズ\n",
        "    seed : int\n",
        "      NumPyの乱数のシード\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self.X = X[shuffle_index]\n",
        "        self.y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self.X[p0:p1], self.y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self.X[p0:p1], self.y[p0:p1]\n",
        "# ハイパーパラメータの設定\n",
        "learning_rate = 0.001\n",
        "batch_size = 10\n",
        "num_epochs = 100\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 1\n",
        "# 計算グラフに渡す引数の形を決める\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "# trainのミニバッチイテレータ\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "def example_net(x):\n",
        "    \"\"\"\n",
        "    単純な3層ニューラルネットワーク\n",
        "    \"\"\"\n",
        "    tf.random.set_random_seed(0)\n",
        "    # 重みとバイアスの宣言\n",
        "    weights = {\n",
        "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
        "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
        "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
        "    }\n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
        "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
        "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
        "    }\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
        "    return layer_output\n",
        "# ネットワーク構造の読み込み                               \n",
        "logits = example_net(X)\n",
        "# 目的関数\n",
        "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n",
        "# 最適化手法\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "# 推定結果\n",
        "correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n",
        "# 指標値計算\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "# variableの初期化\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# 計算グラフの実行\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "        # エポックごとにループ\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int64)\n",
        "        total_loss = 0\n",
        "        total_acc = 0\n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            # ミニバッチごとにループ\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            total_loss += loss\n",
        "        total_loss /= n_samples\n",
        "        val_loss, acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}\".format(epoch, total_loss, val_loss, acc))\n",
        "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
        "    print(\"test_acc : {:.3f}\".format(test_acc))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss : 1.1500, val_loss : 14.0215, acc : 0.500\n",
            "Epoch 1, loss : 0.8897, val_loss : 13.5411, acc : 0.500\n",
            "Epoch 2, loss : 0.7888, val_loss : 11.8243, acc : 0.500\n",
            "Epoch 3, loss : 0.6679, val_loss : 10.8418, acc : 0.562\n",
            "Epoch 4, loss : 0.5637, val_loss : 10.3330, acc : 0.500\n",
            "Epoch 5, loss : 0.5236, val_loss : 9.7076, acc : 0.500\n",
            "Epoch 6, loss : 0.4900, val_loss : 8.9683, acc : 0.562\n",
            "Epoch 7, loss : 0.4322, val_loss : 8.4181, acc : 0.500\n",
            "Epoch 8, loss : 0.3955, val_loss : 7.9386, acc : 0.562\n",
            "Epoch 9, loss : 0.3678, val_loss : 7.5476, acc : 0.562\n",
            "Epoch 10, loss : 0.3364, val_loss : 7.1723, acc : 0.562\n",
            "Epoch 11, loss : 0.3149, val_loss : 6.8348, acc : 0.625\n",
            "Epoch 12, loss : 0.2963, val_loss : 6.5382, acc : 0.625\n",
            "Epoch 13, loss : 0.2774, val_loss : 6.2857, acc : 0.625\n",
            "Epoch 14, loss : 0.2615, val_loss : 6.0683, acc : 0.625\n",
            "Epoch 15, loss : 0.2467, val_loss : 5.8699, acc : 0.625\n",
            "Epoch 16, loss : 0.2322, val_loss : 5.6911, acc : 0.688\n",
            "Epoch 17, loss : 0.2193, val_loss : 5.5466, acc : 0.688\n",
            "Epoch 18, loss : 0.2074, val_loss : 5.4140, acc : 0.688\n",
            "Epoch 19, loss : 0.1978, val_loss : 5.2907, acc : 0.688\n",
            "Epoch 20, loss : 0.1891, val_loss : 5.1763, acc : 0.688\n",
            "Epoch 21, loss : 0.1812, val_loss : 5.0680, acc : 0.688\n",
            "Epoch 22, loss : 0.1740, val_loss : 4.9651, acc : 0.688\n",
            "Epoch 23, loss : 0.1670, val_loss : 4.8642, acc : 0.688\n",
            "Epoch 24, loss : 0.1603, val_loss : 4.7665, acc : 0.688\n",
            "Epoch 25, loss : 0.1539, val_loss : 4.6711, acc : 0.688\n",
            "Epoch 26, loss : 0.1477, val_loss : 4.5804, acc : 0.688\n",
            "Epoch 27, loss : 0.1415, val_loss : 4.4919, acc : 0.688\n",
            "Epoch 28, loss : 0.1357, val_loss : 4.4066, acc : 0.688\n",
            "Epoch 29, loss : 0.1304, val_loss : 4.3264, acc : 0.688\n",
            "Epoch 30, loss : 0.1254, val_loss : 4.2517, acc : 0.688\n",
            "Epoch 31, loss : 0.1207, val_loss : 4.1803, acc : 0.688\n",
            "Epoch 32, loss : 0.1163, val_loss : 4.1159, acc : 0.750\n",
            "Epoch 33, loss : 0.1126, val_loss : 4.0596, acc : 0.750\n",
            "Epoch 34, loss : 0.1090, val_loss : 4.0118, acc : 0.750\n",
            "Epoch 35, loss : 0.1057, val_loss : 3.9709, acc : 0.812\n",
            "Epoch 36, loss : 0.1026, val_loss : 3.9345, acc : 0.812\n",
            "Epoch 37, loss : 0.0997, val_loss : 3.9017, acc : 0.812\n",
            "Epoch 38, loss : 0.0968, val_loss : 3.8702, acc : 0.812\n",
            "Epoch 39, loss : 0.0940, val_loss : 3.8439, acc : 0.812\n",
            "Epoch 40, loss : 0.0914, val_loss : 3.8154, acc : 0.812\n",
            "Epoch 41, loss : 0.0888, val_loss : 3.7834, acc : 0.812\n",
            "Epoch 42, loss : 0.0863, val_loss : 3.7524, acc : 0.812\n",
            "Epoch 43, loss : 0.0838, val_loss : 3.7243, acc : 0.812\n",
            "Epoch 44, loss : 0.0816, val_loss : 3.6904, acc : 0.812\n",
            "Epoch 45, loss : 0.0792, val_loss : 3.6584, acc : 0.812\n",
            "Epoch 46, loss : 0.0771, val_loss : 3.6161, acc : 0.812\n",
            "Epoch 47, loss : 0.0750, val_loss : 3.5727, acc : 0.812\n",
            "Epoch 48, loss : 0.0728, val_loss : 3.5304, acc : 0.812\n",
            "Epoch 49, loss : 0.0705, val_loss : 3.4774, acc : 0.812\n",
            "Epoch 50, loss : 0.0682, val_loss : 3.4291, acc : 0.812\n",
            "Epoch 51, loss : 0.0659, val_loss : 3.4054, acc : 0.812\n",
            "Epoch 52, loss : 0.0641, val_loss : 3.3727, acc : 0.812\n",
            "Epoch 53, loss : 0.0626, val_loss : 3.3410, acc : 0.812\n",
            "Epoch 54, loss : 0.0610, val_loss : 3.3133, acc : 0.812\n",
            "Epoch 55, loss : 0.0597, val_loss : 3.2817, acc : 0.812\n",
            "Epoch 56, loss : 0.0579, val_loss : 3.2601, acc : 0.812\n",
            "Epoch 57, loss : 0.0563, val_loss : 3.2251, acc : 0.812\n",
            "Epoch 58, loss : 0.0546, val_loss : 3.1926, acc : 0.812\n",
            "Epoch 59, loss : 0.0533, val_loss : 3.1684, acc : 0.812\n",
            "Epoch 60, loss : 0.0522, val_loss : 3.1452, acc : 0.812\n",
            "Epoch 61, loss : 0.0509, val_loss : 3.1244, acc : 0.812\n",
            "Epoch 62, loss : 0.0497, val_loss : 3.1038, acc : 0.812\n",
            "Epoch 63, loss : 0.0485, val_loss : 3.0829, acc : 0.812\n",
            "Epoch 64, loss : 0.0474, val_loss : 3.0625, acc : 0.812\n",
            "Epoch 65, loss : 0.0462, val_loss : 3.0417, acc : 0.812\n",
            "Epoch 66, loss : 0.0451, val_loss : 3.0209, acc : 0.812\n",
            "Epoch 67, loss : 0.0440, val_loss : 3.0000, acc : 0.812\n",
            "Epoch 68, loss : 0.0429, val_loss : 2.9789, acc : 0.812\n",
            "Epoch 69, loss : 0.0419, val_loss : 2.9578, acc : 0.812\n",
            "Epoch 70, loss : 0.0409, val_loss : 2.9365, acc : 0.812\n",
            "Epoch 71, loss : 0.0399, val_loss : 2.9150, acc : 0.812\n",
            "Epoch 72, loss : 0.0390, val_loss : 2.8936, acc : 0.812\n",
            "Epoch 73, loss : 0.0381, val_loss : 2.8725, acc : 0.812\n",
            "Epoch 74, loss : 0.0372, val_loss : 2.8509, acc : 0.812\n",
            "Epoch 75, loss : 0.0363, val_loss : 2.8286, acc : 0.812\n",
            "Epoch 76, loss : 0.0354, val_loss : 2.8081, acc : 0.812\n",
            "Epoch 77, loss : 0.0346, val_loss : 2.7872, acc : 0.812\n",
            "Epoch 78, loss : 0.0338, val_loss : 2.7658, acc : 0.812\n",
            "Epoch 79, loss : 0.0330, val_loss : 2.7461, acc : 0.812\n",
            "Epoch 80, loss : 0.0323, val_loss : 2.7256, acc : 0.812\n",
            "Epoch 81, loss : 0.0315, val_loss : 2.7053, acc : 0.812\n",
            "Epoch 82, loss : 0.0308, val_loss : 2.6854, acc : 0.812\n",
            "Epoch 83, loss : 0.0300, val_loss : 2.6655, acc : 0.812\n",
            "Epoch 84, loss : 0.0293, val_loss : 2.6460, acc : 0.812\n",
            "Epoch 85, loss : 0.0286, val_loss : 2.6267, acc : 0.812\n",
            "Epoch 86, loss : 0.0279, val_loss : 2.6075, acc : 0.812\n",
            "Epoch 87, loss : 0.0272, val_loss : 2.5887, acc : 0.812\n",
            "Epoch 88, loss : 0.0265, val_loss : 2.5699, acc : 0.812\n",
            "Epoch 89, loss : 0.0259, val_loss : 2.5513, acc : 0.812\n",
            "Epoch 90, loss : 0.0252, val_loss : 2.5328, acc : 0.812\n",
            "Epoch 91, loss : 0.0246, val_loss : 2.5145, acc : 0.812\n",
            "Epoch 92, loss : 0.0239, val_loss : 2.4962, acc : 0.812\n",
            "Epoch 93, loss : 0.0233, val_loss : 2.4781, acc : 0.812\n",
            "Epoch 94, loss : 0.0227, val_loss : 2.4601, acc : 0.812\n",
            "Epoch 95, loss : 0.0221, val_loss : 2.4381, acc : 0.812\n",
            "Epoch 96, loss : 0.0214, val_loss : 2.4261, acc : 0.812\n",
            "Epoch 97, loss : 0.0210, val_loss : 2.4026, acc : 0.812\n",
            "Epoch 98, loss : 0.0203, val_loss : 2.3886, acc : 0.812\n",
            "Epoch 99, loss : 0.0198, val_loss : 2.3691, acc : 0.812\n",
            "test_acc : 0.850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTcSoM50QfYE"
      },
      "source": [
        "【問題3】3種類全ての目的変数を使用したIrisのモデルを作成<br>\n",
        "参考サイト：<br>\n",
        "https://qiita.com/raso0527/items/4d0f77e816506511469e<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "gCuHrw5PRB-f",
        "outputId": "69fc7484-53bc-4864-be8d-e34621b5524b"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "iris = load_iris()\n",
        "data = iris.data\n",
        "label = iris.target\n",
        "target_name = iris.target_names\n",
        "all_data = np.concatenate([data, label.reshape(-1, 1)], axis=1)\n",
        "print(target_name)\n",
        "\n",
        "train_df = pd.DataFrame(all_data)\n",
        "train = train_df.iloc[:, :]\n",
        "train.rename(columns={0:'SepalLengthCm', 1:'SepalWidthCm', 2:'PetalLengthCm', 3:'PetalWidthCm', 4:'Species'}, inplace=True)\n",
        "train['Species'].replace(0.0, 'Iris-setosa', inplace=True)\n",
        "train['Species'].replace(1.0, 'Iris-versicolor', inplace=True)\n",
        "train['Species'].replace(2.0, 'Iris-virginica', inplace=True)\n",
        "train"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm         Species\n",
              "0              5.1           3.5            1.4           0.2     Iris-setosa\n",
              "1              4.9           3.0            1.4           0.2     Iris-setosa\n",
              "2              4.7           3.2            1.3           0.2     Iris-setosa\n",
              "3              4.6           3.1            1.5           0.2     Iris-setosa\n",
              "4              5.0           3.6            1.4           0.2     Iris-setosa\n",
              "..             ...           ...            ...           ...             ...\n",
              "145            6.7           3.0            5.2           2.3  Iris-virginica\n",
              "146            6.3           2.5            5.0           1.9  Iris-virginica\n",
              "147            6.5           3.0            5.2           2.0  Iris-virginica\n",
              "148            6.2           3.4            5.4           2.3  Iris-virginica\n",
              "149            5.9           3.0            5.1           1.8  Iris-virginica\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fbM2_Of9Njx6",
        "outputId": "0dea11a0-8da4-4337-fb2c-be769dd537e2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "\n",
        "# シード値を固定して実行の度に同じ乱数が発生するようにしている\n",
        "tf.set_random_seed(1000)\n",
        "np.random.seed(1000)\n",
        "sess = tf.Session()\n",
        "\n",
        "# setosa, versicolor, virginicaの分類を行う\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "x_vals = iris.data\n",
        "target = iris.target\n",
        "\n",
        "# ワンホットベクトルの作成\n",
        "y1 = [[1, 0, 0] for i in target if i == 0]\n",
        "y2 = [[0, 1, 0] for i in target if i == 1]\n",
        "y3 = [[0, 0, 1] for i in target if i == 2]\n",
        "\n",
        "y_vals = np.array(y1+y2+y3)\n",
        "\n",
        "learning_rate = 0.05\n",
        "batch_size = 25\n",
        "\n",
        "x_data = tf.placeholder(shape = [None, 4], dtype = tf.float32)\n",
        "y_target = tf.placeholder(shape = [None, 3], dtype = tf.float32)\n",
        "\n",
        "A = tf.Variable(tf.random_normal(shape = [4, 3]))\n",
        "b = tf.Variable(tf.random_normal(shape = [3]))\n",
        "\n",
        "model_output = tf.add(tf.matmul(x_data, A), b)\n",
        "\n",
        "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = model_output, labels = y_target))\n",
        "# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = model_output, labels = y_target))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "train = optimizer.minimize(loss)\n",
        "\n",
        "prediction = tf.round(tf.sigmoid(model_output))\n",
        "prediction_correct = tf.cast(tf.equal(prediction, y_target), tf.float32)\n",
        "accuracy = tf.reduce_mean(prediction_correct)\n",
        "\n",
        "loss_vec = []\n",
        "accuracy_vec = []\n",
        "\n",
        "for i in range(1500):\n",
        "\n",
        "    rand_index = np.random.choice(len(x_vals), size = batch_size)\n",
        "    rand_x = x_vals[rand_index]\n",
        "    rand_y = y_vals[rand_index]\n",
        "\n",
        "    sess.run(train, feed_dict = {x_data: rand_x, y_target: rand_y})\n",
        "\n",
        "    tmp_accuracy, temp_loss = sess.run([accuracy, loss], feed_dict = {x_data: rand_x, y_target: rand_y})\n",
        "\n",
        "    loss_vec.append(temp_loss)\n",
        "    accuracy_vec.append(tmp_accuracy)\n",
        "\n",
        "    if (i + 1) % 25 == 0:\n",
        "\n",
        "        print(\"Step #\" + str(i + 1) + \" A = \" + str(sess.run(A)) + \" b = \" + str(sess.run(b)))\n",
        "        print(\"Loss = \" + str(temp_loss))\n",
        "        print(\"Acc = \" + str(tmp_accuracy))\n",
        "\n",
        "plt.plot(loss_vec, \"k-\")\n",
        "plt.title(\"Loss per Generation\")\n",
        "plt.xlabel(\"Generation\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(accuracy_vec, \"k-\")\n",
        "plt.title(\"Accuracy per Generation\")\n",
        "plt.xlabel(\"Generation\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step #25 A = [[-0.78342134  0.8736729  -0.5325851 ]\n",
            " [-1.5571024  -0.4969507  -0.3290635 ]\n",
            " [-0.4178735  -0.6904336   0.68340737]\n",
            " [ 0.70635015 -1.0762354  -0.0974121 ]] b = [-0.36178365 -0.01402414  0.9880354 ]\n",
            "Loss = 0.9464664\n",
            "Acc = 0.6933333\n",
            "Step #50 A = [[-0.09919751  0.79855895 -0.5832068 ]\n",
            " [-1.0906407  -0.6343527  -0.3764728 ]\n",
            " [-0.22048712 -0.5398163   0.7340515 ]\n",
            " [ 0.73809606 -1.0111351  -0.05770323]] b = [-0.22479635 -0.03999507  0.96858984]\n",
            "Loss = 1.1774287\n",
            "Acc = 0.52\n",
            "Step #75 A = [[ 0.2666577   0.7643704  -0.61555797]\n",
            " [-0.7654588  -0.74460196 -0.41153285]\n",
            " [-0.2580504  -0.3892211   0.78502643]\n",
            " [ 0.69063014 -0.95032966 -0.01910936]] b = [-0.14069709 -0.05603657  0.9532858 ]\n",
            "Loss = 0.69478285\n",
            "Acc = 0.6\n",
            "Step #100 A = [[ 0.33758342  0.72478557 -0.63883626]\n",
            " [-0.6129086  -0.8355862  -0.4363882 ]\n",
            " [-0.46470428 -0.27934572  0.84013873]\n",
            " [ 0.58977354 -0.9075305   0.02295065]] b = [-0.10891949 -0.06990606  0.9397919 ]\n",
            "Loss = 0.5984309\n",
            "Acc = 0.6\n",
            "Step #125 A = [[ 0.39515626  0.68331045 -0.6498669 ]\n",
            " [-0.48184294 -0.91161174 -0.45845792]\n",
            " [-0.6428648  -0.19592482  0.89949876]\n",
            " [ 0.504007   -0.8737353   0.06222998]] b = [-0.08118203 -0.08282821  0.9285077 ]\n",
            "Loss = 0.45451096\n",
            "Acc = 0.81333333\n",
            "Step #150 A = [[ 0.44585076  0.6759953  -0.6911579 ]\n",
            " [-0.36520964 -0.9688235  -0.48947573]\n",
            " [-0.79825395 -0.10564304  0.93167937]\n",
            " [ 0.43058085 -0.84175     0.09279469]] b = [-0.05814159 -0.08860283  0.913695  ]\n",
            "Loss = 0.4522605\n",
            "Acc = 0.7733333\n",
            "Step #175 A = [[ 0.4717887   0.6571022  -0.705901  ]\n",
            " [-0.27989215 -1.0171198  -0.5090145 ]\n",
            " [-0.9329824  -0.04569186  0.97994566]\n",
            " [ 0.36921343 -0.8193906   0.12509699]] b = [-0.04226946 -0.09402729  0.9028985 ]\n",
            "Loss = 0.43039063\n",
            "Acc = 0.81333333\n",
            "Step #200 A = [[ 0.5135492   0.64420706 -0.7416417 ]\n",
            " [-0.19125657 -1.0582615  -0.5386895 ]\n",
            " [-1.0386325   0.00922791  1.0062675 ]\n",
            " [ 0.31868806 -0.80070245  0.15076712]] b = [-0.02466899 -0.09751169  0.8892532 ]\n",
            "Loss = 0.43096778\n",
            "Acc = 0.84\n",
            "Step #225 A = [[ 0.5422542   0.60639554 -0.7458939 ]\n",
            " [-0.12029387 -1.1092032  -0.550939  ]\n",
            " [-1.1336406   0.04038903  1.0537882 ]\n",
            " [ 0.27381676 -0.7909231   0.18364877]] b = [-0.01064404 -0.10513538  0.8809799 ]\n",
            "Loss = 0.37648693\n",
            "Acc = 0.8933333\n",
            "Step #250 A = [[ 0.5650813   0.6022788  -0.77910674]\n",
            " [-0.0600377  -1.1383201  -0.576623  ]\n",
            " [-1.2135222   0.07890826  1.0781214 ]\n",
            " [ 0.23658754 -0.7800007   0.20784506]] b = [ 0.00150273 -0.10610212  0.86838627]\n",
            "Loss = 0.35511345\n",
            "Acc = 0.88\n",
            "Step #275 A = [[ 0.5812815   0.5956878  -0.7978431 ]\n",
            " [-0.00879358 -1.1630318  -0.59583175]\n",
            " [-1.2881229   0.11332121  1.1094601 ]\n",
            " [ 0.20179746 -0.7705472   0.23416816]] b = [ 0.01108721 -0.10634586  0.8579067 ]\n",
            "Loss = 0.3623126\n",
            "Acc = 0.84\n",
            "Step #300 A = [[ 0.58821195  0.5762994  -0.80063885]\n",
            " [ 0.03353744 -1.1935138  -0.60579634]\n",
            " [-1.35869     0.12708084  1.1531394 ]\n",
            " [ 0.17018248 -0.7690425   0.2640364 ]] b = [ 0.01855794 -0.10900015  0.85098535]\n",
            "Loss = 0.34633723\n",
            "Acc = 0.9066667\n",
            "Step #325 A = [[ 0.59817344  0.5895968  -0.8307629 ]\n",
            " [ 0.07271732 -1.2044246  -0.6277632 ]\n",
            " [-1.417866    0.15466917  1.1739069 ]\n",
            " [ 0.14322573 -0.764527    0.28592843]] b = [ 0.02545136 -0.10443915  0.83938   ]\n",
            "Loss = 0.3600973\n",
            "Acc = 0.85333335\n",
            "Step #350 A = [[ 0.6203094   0.5699834  -0.8456432 ]\n",
            " [ 0.11655478 -1.2330557  -0.6420863 ]\n",
            " [-1.4669329   0.16910619  1.2032568 ]\n",
            " [ 0.11996522 -0.7660178   0.31266707]] b = [ 0.03430375 -0.1064353   0.8306661 ]\n",
            "Loss = 0.365825\n",
            "Acc = 0.84\n",
            "Step #375 A = [[ 0.63176334  0.5644549  -0.8578944 ]\n",
            " [ 0.15028614 -1.2505203  -0.65332013]\n",
            " [-1.5145915   0.1799416   1.2348896 ]\n",
            " [ 0.09723391 -0.76884884  0.33915916]] b = [ 0.04094901 -0.10540181  0.82231456]\n",
            "Loss = 0.33905607\n",
            "Acc = 0.8666667\n",
            "Step #400 A = [[ 0.63993925  0.6033178  -0.9077048 ]\n",
            " [ 0.18159701 -1.2485654  -0.68371   ]\n",
            " [-1.5632951   0.23119298  1.2353901 ]\n",
            " [ 0.07447035 -0.757435    0.3546001 ]] b = [ 0.04685897 -0.09839945  0.8086468 ]\n",
            "Loss = 0.33816168\n",
            "Acc = 0.8933333\n",
            "Step #425 A = [[ 0.64160573  0.5833117  -0.9065701 ]\n",
            " [ 0.20614564 -1.2691388  -0.6908265 ]\n",
            " [-1.6089606   0.23060074  1.2733055 ]\n",
            " [ 0.05390374 -0.76276284  0.38176966]] b = [ 0.05058363 -0.09812837  0.8022798 ]\n",
            "Loss = 0.33360624\n",
            "Acc = 0.9066667\n",
            "Step #450 A = [[ 0.65189546  0.5511359  -0.9093088 ]\n",
            " [ 0.23578052 -1.301067   -0.6956948 ]\n",
            " [-1.6478076   0.21538024  1.3115187 ]\n",
            " [ 0.03608773 -0.77275926  0.40775707]] b = [ 0.05615406 -0.10100536  0.7955753 ]\n",
            "Loss = 0.22192396\n",
            "Acc = 0.93333334\n",
            "Step #475 A = [[ 0.6743503   0.54941237 -0.92383367]\n",
            " [ 0.27015838 -1.3154683  -0.7083284 ]\n",
            " [-1.6785039   0.22926332  1.3370429 ]\n",
            " [ 0.02077339 -0.7743151   0.43062356]] b = [ 0.06379259 -0.0998458   0.787646  ]\n",
            "Loss = 0.2715607\n",
            "Acc = 0.92\n",
            "Step #500 A = [[ 0.6689293   0.56175596 -0.9452463 ]\n",
            " [ 0.28725755 -1.3231592  -0.7216008 ]\n",
            " [-1.7197065   0.2432985   1.3571535 ]\n",
            " [ 0.00282547 -0.776704    0.45244303]] b = [ 0.06601945 -0.0953331   0.7784948 ]\n",
            "Loss = 0.2931515\n",
            "Acc = 0.88\n",
            "Step #525 A = [[ 0.6731769   0.5656187  -0.9716629 ]\n",
            " [ 0.30830503 -1.3314872  -0.7384933 ]\n",
            " [-1.7528638   0.24818626  1.3721018 ]\n",
            " [-0.0123596  -0.7808665   0.47046635]] b = [ 0.06964297 -0.09133895  0.76823443]\n",
            "Loss = 0.32058978\n",
            "Acc = 0.84\n",
            "Step #550 A = [[ 0.6775159   0.58146995 -0.9926502 ]\n",
            " [ 0.3282556  -1.3299217  -0.7538367 ]\n",
            " [-1.7846736   0.2629128   1.3901424 ]\n",
            " [-0.02701062 -0.781596    0.4897822 ]] b = [ 0.07320089 -0.08481502  0.7589694 ]\n",
            "Loss = 0.30505812\n",
            "Acc = 0.88\n",
            "Step #575 A = [[ 0.6892011   0.57853216 -1.0085293 ]\n",
            " [ 0.35239014 -1.3409401  -0.76612586]\n",
            " [-1.8118862   0.2636347   1.4135305 ]\n",
            " [-0.0404138  -0.785864    0.50966686]] b = [ 0.07798729 -0.08177642  0.7506052 ]\n",
            "Loss = 0.2713213\n",
            "Acc = 0.8933333\n",
            "Step #600 A = [[ 0.7033154   0.5641392  -1.0115373 ]\n",
            " [ 0.37635207 -1.3567592  -0.7726378 ]\n",
            " [-1.8359121   0.26507968  1.440733  ]\n",
            " [-0.05223236 -0.7912731   0.53172386]] b = [ 0.08304534 -0.08132713  0.7446464 ]\n",
            "Loss = 0.29284522\n",
            "Acc = 0.9066667\n",
            "Step #625 A = [[ 0.70560193  0.5605722  -1.0252103 ]\n",
            " [ 0.39322186 -1.3689238  -0.7830922 ]\n",
            " [-1.864816    0.26551643  1.4625496 ]\n",
            " [-0.06494845 -0.79843456  0.55193925]] b = [ 0.08600821 -0.07895295  0.736871  ]\n",
            "Loss = 0.28777966\n",
            "Acc = 0.8933333\n",
            "Step #650 A = [[ 0.7156215   0.56487226 -1.0471598 ]\n",
            " [ 0.41376373 -1.3781828  -0.7972121 ]\n",
            " [-1.8882244   0.27625352  1.4762013 ]\n",
            " [-0.07586513 -0.8010909   0.56874937]] b = [ 0.0902592  -0.07621888  0.72842306]\n",
            "Loss = 0.27480015\n",
            "Acc = 0.8933333\n",
            "Step #675 A = [[ 0.71073264  0.5725714  -1.0502467 ]\n",
            " [ 0.42463455 -1.3822944  -0.8009734 ]\n",
            " [-1.9167144   0.27781978  1.504259  ]\n",
            " [-0.08815884 -0.808853    0.59172696]] b = [ 0.09146304 -0.07046042  0.72191775]\n",
            "Loss = 0.2766371\n",
            "Acc = 0.8666667\n",
            "Step #700 A = [[ 0.7138875   0.5965368  -1.0858717 ]\n",
            " [ 0.43982404 -1.3804586  -0.81989664]\n",
            " [-1.9415141   0.2986458   1.5088484 ]\n",
            " [-0.09927955 -0.8093436   0.60716915]] b = [ 0.09414818 -0.06305485  0.71086013]\n",
            "Loss = 0.32730722\n",
            "Acc = 0.8666667\n",
            "Step #725 A = [[ 0.71939576  0.55366164 -1.0660421 ]\n",
            " [ 0.4562329  -1.40554    -0.81553197]\n",
            " [-1.9633019   0.2652821   1.5534726 ]\n",
            " [-0.10940322 -0.82741725  0.6350071 ]] b = [ 0.09709134 -0.06652597  0.70907915]\n",
            "Loss = 0.2559915\n",
            "Acc = 0.94666666\n",
            "Step #750 A = [[ 0.7201142   0.5858813  -1.1004207 ]\n",
            " [ 0.4691247  -1.3913573  -0.8379555 ]\n",
            " [-1.9869463   0.28910756  1.5547483 ]\n",
            " [-0.11986507 -0.825312    0.64655   ]] b = [ 0.099078   -0.05558136  0.6972242 ]\n",
            "Loss = 0.3383549\n",
            "Acc = 0.8666667\n",
            "Step #775 A = [[ 0.72451043  0.5744786  -1.1059859 ]\n",
            " [ 0.48352212 -1.4008299  -0.8464198 ]\n",
            " [-2.0073135   0.27994552  1.5789365 ]\n",
            " [-0.12914534 -0.8344349   0.6659907 ]] b = [ 0.1016338  -0.05430604  0.6917635 ]\n",
            "Loss = 0.29715404\n",
            "Acc = 0.85333335\n",
            "Step #800 A = [[ 0.72251236  0.6149236  -1.1405056 ]\n",
            " [ 0.49491173 -1.3897609  -0.8664834 ]\n",
            " [-2.0313923   0.30753636  1.5822208 ]\n",
            " [-0.13978031 -0.83265024  0.67943597]] b = [ 0.10312234 -0.04434189  0.6812662 ]\n",
            "Loss = 0.34741837\n",
            "Acc = 0.84\n",
            "Step #825 A = [[ 0.7331477   0.5855528  -1.1366835 ]\n",
            " [ 0.5123758  -1.4135247  -0.86798155]\n",
            " [-2.0477157   0.2903882   1.6114969 ]\n",
            " [-0.14777344 -0.8448869   0.7014615 ]] b = [ 0.10676939 -0.04590752  0.67674017]\n",
            "Loss = 0.30877683\n",
            "Acc = 0.84\n",
            "Step #850 A = [[ 0.7368144   0.59750086 -1.1618806 ]\n",
            " [ 0.5258775  -1.4198586  -0.88219833]\n",
            " [-2.0671518   0.30286652  1.6187484 ]\n",
            " [-0.15631364 -0.84851474  0.7163014 ]] b = [ 0.10918387 -0.04155568  0.66805136]\n",
            "Loss = 0.29543257\n",
            "Acc = 0.81333333\n",
            "Step #875 A = [[ 0.74066365  0.59463423 -1.1746465 ]\n",
            " [ 0.5386737  -1.4245615  -0.8929903 ]\n",
            " [-2.0849712   0.29642144  1.6371896 ]\n",
            " [-0.16430233 -0.8572328   0.73354757]] b = [ 0.11142129 -0.03711697  0.6604269 ]\n",
            "Loss = 0.29959115\n",
            "Acc = 0.84\n",
            "Step #900 A = [[ 0.7476288   0.60399055 -1.1823636 ]\n",
            " [ 0.5531003  -1.4317281  -0.8980838 ]\n",
            " [-2.1006606   0.3062602   1.6571054 ]\n",
            " [-0.17181778 -0.86168236  0.7523954 ]] b = [ 0.11427306 -0.03271515  0.65429676]\n",
            "Loss = 0.25045744\n",
            "Acc = 0.8933333\n",
            "Step #925 A = [[ 0.7436538   0.62002486 -1.2011507 ]\n",
            " [ 0.561458   -1.4308994  -0.91007805]\n",
            " [-2.1222212   0.31247875  1.6712358 ]\n",
            " [-0.1813368  -0.867661    0.7693093 ]] b = [ 0.11516114 -0.02645336  0.6464977 ]\n",
            "Loss = 0.2914851\n",
            "Acc = 0.85333335\n",
            "Step #950 A = [[ 0.7461054   0.6105291  -1.2090826 ]\n",
            " [ 0.5725567  -1.4424148  -0.91737473]\n",
            " [-2.139339    0.3051311   1.691662  ]\n",
            " [-0.18897992 -0.8795775   0.7885887 ]] b = [ 0.11710376 -0.02457586  0.64034367]\n",
            "Loss = 0.32366407\n",
            "Acc = 0.85333335\n",
            "Step #975 A = [[ 0.75746465  0.5889624  -1.2115483 ]\n",
            " [ 0.5886753  -1.462823   -0.9194608 ]\n",
            " [-2.151927    0.2935234   1.7167566 ]\n",
            " [-0.19535777 -0.8887326   0.8076301 ]] b = [ 0.12077887 -0.02492964  0.63497907]\n",
            "Loss = 0.213989\n",
            "Acc = 0.94666666\n",
            "Step #1000 A = [[ 0.7633197   0.6035117  -1.2327155 ]\n",
            " [ 0.60192883 -1.4637789  -0.9333892 ]\n",
            " [-2.167576    0.31536838  1.7225296 ]\n",
            " [-0.2026903  -0.8869312   0.82014316]] b = [ 0.12338338 -0.01924964  0.62651366]\n",
            "Loss = 0.2905844\n",
            "Acc = 0.84\n",
            "Step #1025 A = [[ 0.7657181   0.60546845 -1.2379066 ]\n",
            " [ 0.6125206  -1.4691445  -0.9395942 ]\n",
            " [-2.184122    0.31931478  1.743246  ]\n",
            " [-0.21028179 -0.891713    0.8376883 ]] b = [ 0.12520981 -0.01479279  0.6204564 ]\n",
            "Loss = 0.26944596\n",
            "Acc = 0.85333335\n",
            "Step #1050 A = [[ 0.76379895  0.6146481  -1.2564962 ]\n",
            " [ 0.62029535 -1.4724952  -0.9498212 ]\n",
            " [-2.2014601   0.32023868  1.7541883 ]\n",
            " [-0.2177387  -0.8987464   0.8525865 ]] b = [ 0.12617591 -0.01032528  0.61321145]\n",
            "Loss = 0.24760368\n",
            "Acc = 0.8933333\n",
            "Step #1075 A = [[ 0.7637699   0.6189678  -1.2671134 ]\n",
            " [ 0.6287687  -1.4780316  -0.9559038 ]\n",
            " [-2.218198    0.3200827   1.7705503 ]\n",
            " [-0.22515611 -0.90691847  0.87004757]] b = [ 0.12746371 -0.00548448  0.60660243]\n",
            "Loss = 0.3027512\n",
            "Acc = 0.8666667\n",
            "Step #1100 A = [[ 0.76584643  0.6113466  -1.2700522 ]\n",
            " [ 0.6386048  -1.489534   -0.95919114]\n",
            " [-2.2326305   0.3109592   1.792426  ]\n",
            " [-0.2317756  -0.91515696  0.88815165]] b = [ 0.12914345 -0.00380917  0.6018638 ]\n",
            "Loss = 0.27831823\n",
            "Acc = 0.85333335\n",
            "Step #1125 A = [[ 0.7759232   0.61459213 -1.2885929 ]\n",
            " [ 0.65291774 -1.4940085  -0.9718328 ]\n",
            " [-2.2439651   0.32087478  1.8004919 ]\n",
            " [-0.23759891 -0.9164966   0.9004539 ]] b = [ 1.3236180e-01 -2.2453826e-04  5.9452194e-01]\n",
            "Loss = 0.24810208\n",
            "Acc = 0.93333334\n",
            "Step #1150 A = [[ 0.7699655   0.6322938  -1.2971485 ]\n",
            " [ 0.65704596 -1.4893758  -0.97916496]\n",
            " [-2.2615452   0.330118    1.8176045 ]\n",
            " [-0.2447217  -0.9235042   0.91927737]] b = [0.13236006 0.00738808 0.5879694 ]\n",
            "Loss = 0.24691568\n",
            "Acc = 0.9066667\n",
            "Step #1175 A = [[ 0.77574813  0.5968121  -1.2883538 ]\n",
            " [ 0.66805655 -1.5061549  -0.97973573]\n",
            " [-2.272974    0.2956366   1.8485293 ]\n",
            " [-0.24992616 -0.94090515  0.938737  ]] b = [0.13454963 0.00592847 0.58462423]\n",
            "Loss = 0.24142252\n",
            "Acc = 0.8933333\n",
            "Step #1200 A = [[ 0.7797365   0.63353586 -1.3211058 ]\n",
            " [ 0.6781351  -1.4966139  -0.996402  ]\n",
            " [-2.2851412   0.32038325  1.8464011 ]\n",
            " [-0.25552726 -0.9406764   0.9493846 ]] b = [0.13652372 0.01468951 0.5753157 ]\n",
            "Loss = 0.26148385\n",
            "Acc = 0.85333335\n",
            "Step #1225 A = [[ 0.77281845  0.64401543 -1.3357933 ]\n",
            " [ 0.68194884 -1.4941711  -1.0072554 ]\n",
            " [-2.3027835   0.3208266   1.8586366 ]\n",
            " [-0.2630906  -0.9460417   0.96318215]] b = [0.13627638 0.02021031 0.56914145]\n",
            "Loss = 0.26822573\n",
            "Acc = 0.88\n",
            "Step #1250 A = [[ 0.77847254  0.6507068  -1.3512803 ]\n",
            " [ 0.6925154  -1.5010366  -1.0174805 ]\n",
            " [-2.3137398   0.33078358  1.8690081 ]\n",
            " [-0.2684682  -0.94792986  0.9760212 ]] b = [0.13847692 0.02235495 0.56325334]\n",
            "Loss = 0.26810485\n",
            "Acc = 0.8933333\n",
            "Step #1275 A = [[ 0.7846273   0.6376797  -1.3592758 ]\n",
            " [ 0.70351285 -1.5171168  -1.0224507 ]\n",
            " [-2.3246207   0.32232898  1.8857079 ]\n",
            " [-0.27374426 -0.95581794  0.9912278 ]] b = [0.14076926 0.02248475 0.5578775 ]\n",
            "Loss = 0.19767001\n",
            "Acc = 0.92\n",
            "Step #1300 A = [[ 0.79072267  0.6410509  -1.3588421 ]\n",
            " [ 0.71350443 -1.518418   -1.0266311 ]\n",
            " [-2.3346941   0.3264251   1.9071562 ]\n",
            " [-0.2787234  -0.96203786  1.0087628 ]] b = [0.14295939 0.02578033 0.5540315 ]\n",
            "Loss = 0.24463016\n",
            "Acc = 0.9066667\n",
            "Step #1325 A = [[ 0.7906426   0.6518189  -1.3735653 ]\n",
            " [ 0.7200691  -1.5155191  -1.0381695 ]\n",
            " [-2.3474143   0.33307976  1.9165446 ]\n",
            " [-0.28436482 -0.96599334  1.0215809 ]] b = [0.14392148 0.03165789 0.54709816]\n",
            "Loss = 0.27165627\n",
            "Acc = 0.84\n",
            "Step #1350 A = [[ 0.7930127   0.6441946  -1.3762727 ]\n",
            " [ 0.728688   -1.5236517  -1.0437807 ]\n",
            " [-2.35928     0.32765386  1.9351549 ]\n",
            " [-0.29001144 -0.9745001   1.0379577 ]] b = [0.14544636 0.03382414 0.5422237 ]\n",
            "Loss = 0.27339303\n",
            "Acc = 0.88\n",
            "Step #1375 A = [[ 0.79589224  0.6355193  -1.3878869 ]\n",
            " [ 0.73666024 -1.5291567  -1.0526597 ]\n",
            " [-2.3699381   0.31260836  1.9486399 ]\n",
            " [-0.29484805 -0.98510283  1.0507914 ]] b = [0.14704174 0.03606444 0.53626245]\n",
            "Loss = 0.29112998\n",
            "Acc = 0.84\n",
            "Step #1400 A = [[ 0.79809743  0.6442589  -1.3956296 ]\n",
            " [ 0.74442065 -1.5335252  -1.0579885 ]\n",
            " [-2.3812451   0.32299516  1.9632275 ]\n",
            " [-0.300107   -0.99095654  1.0670792 ]] b = [0.14848353 0.0403027  0.53061885]\n",
            "Loss = 0.2785252\n",
            "Acc = 0.9066667\n",
            "Step #1425 A = [[ 0.8021818   0.6310998  -1.3940119 ]\n",
            " [ 0.7530431  -1.5440516  -1.0597208 ]\n",
            " [-2.391038    0.31129915  1.9858913 ]\n",
            " [-0.30474797 -1.0013348   1.0843735 ]] b = [0.15018603 0.04233512 0.5265404 ]\n",
            "Loss = 0.21894877\n",
            "Acc = 0.8666667\n",
            "Step #1450 A = [[ 0.8041794   0.6571874  -1.4353837 ]\n",
            " [ 0.7608852  -1.5344595  -1.0843617 ]\n",
            " [-2.40229     0.33491126  1.9718689 ]\n",
            " [-0.30973673 -0.9991459   1.0892761 ]] b = [0.15158153 0.05131391 0.5147268 ]\n",
            "Loss = 0.23880613\n",
            "Acc = 0.8933333\n",
            "Step #1475 A = [[ 0.802413    0.6389249  -1.4224205 ]\n",
            " [ 0.7657744  -1.5477662  -1.0816511 ]\n",
            " [-2.4143355   0.3178052   2.0018036 ]\n",
            " [-0.31497237 -1.0127819   1.109724  ]] b = [0.15209478 0.05149637 0.51285505]\n",
            "Loss = 0.23127256\n",
            "Acc = 0.9066667\n",
            "Step #1500 A = [[ 0.80730593  0.64894944 -1.4420232 ]\n",
            " [ 0.77444685 -1.5510545  -1.094136  ]\n",
            " [-2.4235268   0.33464363  2.0048647 ]\n",
            " [-0.31932852 -1.0137881   1.1205004 ]] b = [0.15391421 0.05597487 0.5054383 ]\n",
            "Loss = 0.23429626\n",
            "Acc = 0.9066667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNQueoXPU3Fe"
      },
      "source": [
        "【問題4】House Pricesのモデルを作成<br>\n",
        "参考サイト：<br>\n",
        "https://www.tensorflow.org/tutorials/keras/regression?hl=ja<br>\n",
        "https://qiita.com/SwitchBlade/items/6677c283b2402d060cd0<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_54HTbNoVj8b",
        "outputId": "e69c1f08-ae4a-449e-d819-2e5bb05acad0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "uny5Zfj5Ukjb",
        "outputId": "d5a12240-7d98-47e7-ed9f-a4e86f92e758"
      },
      "source": [
        "DIR_PATH = '/content/drive/My Drive/Colab Notebooks/house-prices-advanced-regression-techniques/'\n",
        "train = pd.read_csv(DIR_PATH+'train.csv')\n",
        "test = pd.read_csv(DIR_PATH+'test.csv')\n",
        "train"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>...</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>196.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>706</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>978</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>486</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>655</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>1456</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>62.0</td>\n",
              "      <td>7917</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Gilbert</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1999</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>953</td>\n",
              "      <td>953</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>953</td>\n",
              "      <td>694</td>\n",
              "      <td>0</td>\n",
              "      <td>1647</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1999.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>1457</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>85.0</td>\n",
              "      <td>13175</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NWAmes</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1978</td>\n",
              "      <td>1988</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Plywood</td>\n",
              "      <td>Plywood</td>\n",
              "      <td>Stone</td>\n",
              "      <td>119.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>790</td>\n",
              "      <td>Rec</td>\n",
              "      <td>163</td>\n",
              "      <td>589</td>\n",
              "      <td>1542</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>2073</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2073</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>7</td>\n",
              "      <td>Min1</td>\n",
              "      <td>2</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1978.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>2</td>\n",
              "      <td>500</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>349</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>1458</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>66.0</td>\n",
              "      <td>9042</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>1941</td>\n",
              "      <td>2006</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>CemntBd</td>\n",
              "      <td>CmentBd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Stone</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>275</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>877</td>\n",
              "      <td>1152</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1188</td>\n",
              "      <td>1152</td>\n",
              "      <td>0</td>\n",
              "      <td>2340</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>2</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1941.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>1</td>\n",
              "      <td>252</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GdPrv</td>\n",
              "      <td>Shed</td>\n",
              "      <td>2500</td>\n",
              "      <td>5</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>266500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>1459</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>9717</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NAmes</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1950</td>\n",
              "      <td>1996</td>\n",
              "      <td>Hip</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>49</td>\n",
              "      <td>Rec</td>\n",
              "      <td>1029</td>\n",
              "      <td>0</td>\n",
              "      <td>1078</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>FuseA</td>\n",
              "      <td>1078</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1078</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>5</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1950.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>1</td>\n",
              "      <td>240</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>366</td>\n",
              "      <td>0</td>\n",
              "      <td>112</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>142125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>1460</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>75.0</td>\n",
              "      <td>9937</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Edwards</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1965</td>\n",
              "      <td>1965</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>BLQ</td>\n",
              "      <td>830</td>\n",
              "      <td>LwQ</td>\n",
              "      <td>290</td>\n",
              "      <td>136</td>\n",
              "      <td>1256</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1256</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1256</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1965.0</td>\n",
              "      <td>Fin</td>\n",
              "      <td>1</td>\n",
              "      <td>276</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>736</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>147500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1460 rows × 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Id  MSSubClass MSZoning  ...  SaleType  SaleCondition SalePrice\n",
              "0        1          60       RL  ...        WD         Normal    208500\n",
              "1        2          20       RL  ...        WD         Normal    181500\n",
              "2        3          60       RL  ...        WD         Normal    223500\n",
              "3        4          70       RL  ...        WD        Abnorml    140000\n",
              "4        5          60       RL  ...        WD         Normal    250000\n",
              "...    ...         ...      ...  ...       ...            ...       ...\n",
              "1455  1456          60       RL  ...        WD         Normal    175000\n",
              "1456  1457          20       RL  ...        WD         Normal    210000\n",
              "1457  1458          70       RL  ...        WD         Normal    266500\n",
              "1458  1459          20       RL  ...        WD         Normal    142125\n",
              "1459  1460          20       RL  ...        WD         Normal    147500\n",
              "\n",
              "[1460 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y3aujIPViYN"
      },
      "source": [
        "X = train[['GrLivArea', 'YearBuilt']]\n",
        "y = train[['SalePrice']]\n",
        "x_test = test[['GrLivArea', 'YearBuilt']]"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T40UjwjgYs4H",
        "outputId": "b5a3d3e6-efce-4c66-8462-01db5dcc1c31"
      },
      "source": [
        "\"\"\"\n",
        "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "# データフレームから条件抽出\n",
        "X = train[['GrLivArea', 'YearBuilt', 'SalePrice']]\n",
        "\n",
        "train_dataset = X.sample(frac=0.8,random_state=0)\n",
        "test_dataset = X.drop(train_dataset.index)\n",
        "\n",
        "train_labels = train_dataset.pop('SalePrice')\n",
        "test_labels = test_dataset.pop('SalePrice')\n",
        "\n",
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "# エポックが終わるごとにドットを一つ出力することで進捗を表示\n",
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  train_dataset, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[PrintDot()])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "....................................................................................................\n",
            "....................................................................................................\n",
            "....................................................................................................\n",
            "....................................................................................................\n",
            "....................................................................................................\n",
            "....................................................................................................\n",
            "....................................................................................................\n",
            "....................................................................................................\n",
            "....................................................................................................\n",
            "...................................................................................................."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "LvRU4ypWrmye",
        "outputId": "1e712a50-d18b-4fe5-ae7b-2bd60e8baa0f"
      },
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mean_absolute_error</th>\n",
              "      <th>mean_squared_error</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mean_absolute_error</th>\n",
              "      <th>val_mean_squared_error</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>3.333751e+09</td>\n",
              "      <td>39201.402344</td>\n",
              "      <td>3.333751e+09</td>\n",
              "      <td>3.063479e+09</td>\n",
              "      <td>38262.617188</td>\n",
              "      <td>3.063479e+09</td>\n",
              "      <td>995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>3.319546e+09</td>\n",
              "      <td>39059.910156</td>\n",
              "      <td>3.319546e+09</td>\n",
              "      <td>3.107206e+09</td>\n",
              "      <td>39441.765625</td>\n",
              "      <td>3.107206e+09</td>\n",
              "      <td>996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>3.324858e+09</td>\n",
              "      <td>39170.570312</td>\n",
              "      <td>3.324858e+09</td>\n",
              "      <td>3.066965e+09</td>\n",
              "      <td>38631.125000</td>\n",
              "      <td>3.066965e+09</td>\n",
              "      <td>997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>3.330439e+09</td>\n",
              "      <td>39202.699219</td>\n",
              "      <td>3.330440e+09</td>\n",
              "      <td>3.062772e+09</td>\n",
              "      <td>38374.554688</td>\n",
              "      <td>3.062772e+09</td>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>3.323166e+09</td>\n",
              "      <td>39040.640625</td>\n",
              "      <td>3.323166e+09</td>\n",
              "      <td>3.061470e+09</td>\n",
              "      <td>38500.285156</td>\n",
              "      <td>3.061469e+09</td>\n",
              "      <td>999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             loss  mean_absolute_error  ...  val_mean_squared_error  epoch\n",
              "995  3.333751e+09         39201.402344  ...            3.063479e+09    995\n",
              "996  3.319546e+09         39059.910156  ...            3.107206e+09    996\n",
              "997  3.324858e+09         39170.570312  ...            3.066965e+09    997\n",
              "998  3.330439e+09         39202.699219  ...            3.062772e+09    998\n",
              "999  3.323166e+09         39040.640625  ...            3.061469e+09    999\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg91VoaKtWEj"
      },
      "source": [
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [MPG]')\n",
        "  plt.plot(hist['epoch'], hist['mae'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mae'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,5])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "  plt.plot(hist['epoch'], hist['mse'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mse'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,20])\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "GHeDO-EKtba9",
        "outputId": "0efea66e-08af-4f2a-bdc7-e370b4d24908"
      },
      "source": [
        "test_predictions = model.predict(test_dataset).flatten()\n",
        "\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [SalePrice]')\n",
        "plt.ylabel('Predictions [SalePrice]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI0AFey8tllY",
        "outputId": "a5356596-fe37-4efb-eeaf-502cafec0061"
      },
      "source": [
        "error = test_predictions - test_labels\n",
        "print(f'予測した結果と正解データとのの誤差: {np.sum(error)}')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "予測した結果と正解データとのの誤差: 1840203.4765625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvGTSefluES2"
      },
      "source": [
        "【問題5】MNISTのモデルを作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFGeOXepty-g",
        "outputId": "cca74e2a-45e5-4d3e-dffe-1e49ec23be60"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFJSblKzwxZK"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8hUOtucxC-o",
        "outputId": "b072ea6e-ad38-48f9-8345-d1484ee5fde7"
      },
      "source": [
        "predictions = model(x_train[:1])\n",
        "predictions"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'sequential_4_2/dense_13/BiasAdd:0' shape=(1, 10) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpct_LCIw3-4",
        "outputId": "fad86b92-73bc-49c0-d3f6-839aad456392"
      },
      "source": [
        "tf.nn.softmax(predictions)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Softmax_1:0' shape=(1, 10) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUtuLFY5w_zT",
        "outputId": "6ee90f76-770b-405a-975f-4b7b535748ea"
      },
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "loss_fn"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.losses.SparseCategoricalCrossentropy at 0x7f8e0b265f90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fodJHIQxLqZ",
        "outputId": "5938537d-bb4a-4c88-e03a-64f837041056"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.2955 - acc: 0.9146\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.1455 - acc: 0.9568\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.1067 - acc: 0.9677\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0887 - acc: 0.9721\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0743 - acc: 0.9766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8e0b2834d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ3F-RihxVol",
        "outputId": "d6cbed87-9f26-4d6b-c878-26bb9ec95728"
      },
      "source": [
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 - 0s - loss: 0.0816 - acc: 0.9764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08164553142033983, 0.9764]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAAQqBjuxgMv",
        "outputId": "7b6d4155-9eae-4047-c791-17abf73ef464"
      },
      "source": [
        "# モデルが確率を返すようにする\n",
        "probability_model = tf.keras.Sequential([\n",
        "  model,\n",
        "  tf.keras.layers.Softmax()\n",
        "])\n",
        "probability_model(x_test[:5])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'sequential_8/softmax_3/Softmax:0' shape=(5, 10) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOgslLLNClyD"
      },
      "source": [
        "### 後で熟読して1系→2系への書き換えに挑む\n",
        "https://www.tensorflow.org/guide/migrate<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knt0DpNGxsfB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}